#include "funasr_engine.h"
#include <random>
#include <cmath>
#include <future>

FunASREngine::FunASREngine(const Config& config) : config_(config) {
    Logger::Info("åˆ›å»ºFunASRå¼•æ“ï¼Œè®¾å¤‡: {}, éŸ³é¢‘ç›®å½•: {}", config_.device, config_.audio_files_dir);
}

FunASREngine::~FunASREngine() {
    testing_active_ = false;
    if (test_thread_.joinable()) {
        test_thread_.join();
    }
    Logger::Info("FunASRå¼•æ“å·²é”€æ¯");
}

bool FunASREngine::Initialize() {
    Logger::Info("åˆå§‹åŒ–FunASRå¼•æ“...");
    Timer init_timer;
    
    try {
        // 1. åˆå§‹åŒ–Pythonç¯å¢ƒ
        if (!InitializePython()) {
            Logger::Error("Pythonç¯å¢ƒåˆå§‹åŒ–å¤±è´¥");
            return false;
        }
        
        // 2. åŠ è½½æ‰€æœ‰FunASRæ¨¡å‹ (æŒ‰ç…§FunASR WebSocketæœåŠ¡å™¨çš„æ ‡å‡†é…ç½®)
        Logger::Info("åŠ è½½FunASRæ¨¡å‹ç»„ä»¶...");
        
        // åŠ è½½æµå¼ASRæ¨¡å‹ (å¯¹åº”FunASR WebSocketä¸­çš„model_asr_streaming)
        if (!LoadFunASRModel("streaming_asr", config_.streaming_model, 
                            config_.streaming_revision, streaming_model_)) {
            Logger::Error("æµå¼ASRæ¨¡å‹åŠ è½½å¤±è´¥");
            return false;
        }
        
        // åŠ è½½ç¦»çº¿ASRæ¨¡å‹ (å¯¹åº”FunASR WebSocketä¸­çš„model_asr)
        if (!LoadFunASRModel("offline_asr", config_.offline_model, 
                            config_.offline_revision, offline_model_)) {
            Logger::Error("ç¦»çº¿ASRæ¨¡å‹åŠ è½½å¤±è´¥");
            return false;
        }
        
        // åŠ è½½VADæ¨¡å‹ (å¯¹åº”FunASR WebSocketä¸­çš„model_vad)
        if (!LoadFunASRModel("vad", config_.vad_model, 
                            config_.vad_revision, vad_model_)) {
            Logger::Error("VADæ¨¡å‹åŠ è½½å¤±è´¥");
            return false;
        }
        
        // åŠ è½½æ ‡ç‚¹ç¬¦å·æ¨¡å‹ (å¯¹åº”FunASR WebSocketä¸­çš„model_punc)
        if (!LoadFunASRModel("punctuation", config_.punc_model, 
                            config_.punc_revision, punc_model_)) {
            Logger::Error("æ ‡ç‚¹ç¬¦å·æ¨¡å‹åŠ è½½å¤±è´¥");
            return false;
        }
        
        // 3. æ£€æŸ¥GPUçŠ¶æ€
        double gpu_memory = GetGPUMemoryUsage();
        Logger::Info("GPUæ˜¾å­˜ä½¿ç”¨: {:.1f}GB", gpu_memory);
        
        // 4. åŠ è½½æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
        if (!LoadTestAudioFiles()) {
            Logger::Error("åŠ è½½æµ‹è¯•éŸ³é¢‘æ–‡ä»¶å¤±è´¥");
            return false;
        }
        
        // 5. åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡
        current_metrics_.gpu_memory_gb = gpu_memory;
        current_metrics_.test_files_count = test_audio_files_.size();
        
        initialized_ = true;
        Logger::Info("FunASRå¼•æ“åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {:.1f}ms", init_timer.ElapsedMs());
        Logger::Info("å·²åŠ è½½æ¨¡å‹: æµå¼ASR + ç¦»çº¿ASR + VAD + æ ‡ç‚¹ç¬¦å·");
        Logger::Info("æµ‹è¯•éŸ³é¢‘æ–‡ä»¶: {}ä¸ª", test_audio_files_.size());
        
        return true;
        
    } catch (const std::exception& e) {
        Logger::Error("å¼•æ“åˆå§‹åŒ–å¼‚å¸¸: {}", e.what());
        return false;
    }
}

bool FunASREngine::InitializePython() {
    try {
        // åˆ›å»ºPythonè§£é‡Šå™¨ï¼ˆpybind11æ ¸å¿ƒåŠŸèƒ½ï¼‰
        py_guard_ = std::make_unique<py::scoped_interpreter>();
        
        // å¯¼å…¥å¿…è¦æ¨¡å—
        py::module_ sys = py::module_::import("sys");
        py::module_ funasr = py::module_::import("funasr");
        py::module_ torch = py::module_::import("torch");
        
        // æ£€æŸ¥CUDAå¯ç”¨æ€§
        bool cuda_available = torch.attr("cuda").attr("is_available")().cast<bool>();
        if (!cuda_available) {
            Logger::Error("CUDAä¸å¯ç”¨ï¼è¯·æ£€æŸ¥PyTorch CUDAå®‰è£…");
            return false;
        }
        
        // è®¾ç½®CUDAè®¾å¤‡
        int device_id = 0;
        if (config_.device.find("cuda:") == 0) {
            device_id = std::stoi(config_.device.substr(5));
        }
        torch.attr("cuda").attr("set_device")(device_id);
        
        // æ£€æŸ¥GPUè®¾å¤‡ä¿¡æ¯
        py::object device_name = torch.attr("cuda").attr("get_device_name")(device_id);
        Logger::Info("Pythonç¯å¢ƒåˆå§‹åŒ–æˆåŠŸ");
        Logger::Info("CUDAè®¾å¤‡: {} - {}", device_id, device_name.cast<std::string>());
        
        return true;
        
    } catch (const py::error_already_set& e) {
        Logger::Error("Pythonåˆå§‹åŒ–å¤±è´¥: {}", e.what());
        return false;
    }
}

bool FunASREngine::LoadFunASRModel(const std::string& model_type, 
                                   const std::string& model_name,
                                   const std::string& model_revision,
                                   py::object& model_obj) {
    try {
        Logger::Info("åŠ è½½{}æ¨¡å‹: {} (ç‰ˆæœ¬: {})", model_type, model_name, model_revision);
        Timer load_timer;
        
        // ä½¿ç”¨FunASRçš„AutoModelç±» (å¯¹åº”FunASRæ ‡å‡†ç”¨æ³•)
        py::module_ funasr = py::module_::import("funasr");
        py::object auto_model = funasr.attr("AutoModel");
        
        // æ„å»ºæ¨¡å‹å‚æ•° (ä¸¥æ ¼æŒ‰ç…§FunASR WebSocketæœåŠ¡å™¨çš„é…ç½®)
        py::dict kwargs;
        kwargs["model"] = model_name;
        kwargs["model_revision"] = model_revision;
        kwargs["device"] = config_.device;
        kwargs["ngpu"] = 1;               // ä½¿ç”¨1ä¸ªGPU
        kwargs["ncpu"] = 4;               // ä½¿ç”¨4ä¸ªCPUæ ¸å¿ƒ (å¯¹åº”FunASRé»˜è®¤)
        kwargs["disable_pbar"] = true;    // ç¦ç”¨è¿›åº¦æ¡
        kwargs["disable_log"] = true;     // ç¦ç”¨å†—ä½™æ—¥å¿—
        
        // é’ˆå¯¹ä¸åŒæ¨¡å‹ç±»å‹çš„ç‰¹æ®Šé…ç½®
        if (model_type == "streaming_asr") {
            // æµå¼ASRæ¨¡å‹æ— éœ€ç‰¹æ®Šé…ç½®ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
        } else if (model_type == "offline_asr") {
            // ç¦»çº¿ASRæ¨¡å‹æ— éœ€ç‰¹æ®Šé…ç½®
        } else if (model_type == "vad") {
            // VADæ¨¡å‹å¯ä»¥è®¾ç½®åˆ†å—å¤§å°
            // kwargs["chunk_size"] = 60;  // å¯é€‰å‚æ•°
        } else if (model_type == "punctuation") {
            // æ ‡ç‚¹ç¬¦å·æ¨¡å‹æ— éœ€ç‰¹æ®Šé…ç½®
        }
        
        // å®ä¾‹åŒ–æ¨¡å‹
        model_obj = auto_model(**kwargs);
        
        Logger::Info("{}æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {:.1f}ms", model_type, load_timer.ElapsedMs());
        return true;
        
    } catch (const py::error_already_set& e) {
        Logger::Error("{}æ¨¡å‹åŠ è½½å¤±è´¥: {}", model_type, e.what());
        return false;
    }
}

bool FunASREngine::LoadTestAudioFiles() {
    Logger::Info("æ‰«ææµ‹è¯•éŸ³é¢‘æ–‡ä»¶ç›®å½•: {}", config_.audio_files_dir);
    
    // æ‰«æWAVæ–‡ä»¶
    auto all_wav_files = AudioFileReader::ScanWavFiles(config_.audio_files_dir);
    
    if (all_wav_files.empty()) {
        Logger::Error("æœªæ‰¾åˆ°WAVéŸ³é¢‘æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ç›®å½•: {}", config_.audio_files_dir);
        return false;
    }
    
    // é€‰æ‹©æµ‹è¯•æ–‡ä»¶ (å¦‚æœæ–‡ä»¶å¤ªå¤šï¼Œéšæœºé€‰æ‹©ä¸€éƒ¨åˆ†)
    if (all_wav_files.size() > static_cast<size_t>(config_.max_test_files)) {
        Logger::Info("éŸ³é¢‘æ–‡ä»¶æ€»æ•°({})è¶…è¿‡æœ€å¤§æµ‹è¯•æ•°({}), å°†éšæœºé€‰æ‹©", 
                    all_wav_files.size(), config_.max_test_files);
        
        // éšæœºæ‰“ä¹±å¹¶é€‰æ‹©å‰Nä¸ª
        std::random_device rd;
        std::mt19937 gen(rd());
        std::shuffle(all_wav_files.begin(), all_wav_files.end(), gen);
        all_wav_files.resize(config_.max_test_files);
    }
    
    test_audio_files_ = std::move(all_wav_files);
    
    Logger::Info("å·²é€‰æ‹©{}ä¸ªéŸ³é¢‘æ–‡ä»¶ç”¨äºæµ‹è¯•", test_audio_files_.size());
    
    // é¢„æ£€æŸ¥å‡ ä¸ªæ–‡ä»¶ç¡®ä¿å¯è¯»æ€§
    int valid_files = 0;
    for (int i = 0; i < std::min(5, static_cast<int>(test_audio_files_.size())); ++i) {
        auto audio_data = AudioFileReader::ReadWavFile(test_audio_files_[i]);
        if (audio_data.IsValid()) {
            valid_files++;
        }
    }
    
    if (valid_files == 0) {
        Logger::Error("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶å¯ä¾›æµ‹è¯•");
        return false;
    }
    
    Logger::Info("éŸ³é¢‘æ–‡ä»¶é¢„æ£€æŸ¥å®Œæˆï¼Œæœ‰æ•ˆæ–‡ä»¶ç‡: {}/5", valid_files);
    return true;
}

// ============ æ ¸å¿ƒè¯†åˆ«åŠŸèƒ½å®ç° ============

FunASREngine::RecognitionResult FunASREngine::OfflineRecognize(
    const std::vector<float>& audio_data,
    bool enable_vad,
    bool enable_punctuation) {
    
    RecognitionResult result;
    if (!initialized_) {
        Logger::Error("å¼•æ“æœªåˆå§‹åŒ–");
        return result;
    }
    
    try {
        Timer total_timer;
        std::string final_text;
        
        if (enable_vad && audio_data.size() > 16000 * 5) {  // å¤§äº5ç§’çš„éŸ³é¢‘å¯ç”¨VAD
            Logger::Info("é•¿éŸ³é¢‘æ£€æµ‹ï¼Œå¯ç”¨VADåˆ†æ®µå¤„ç†");
            
            // 1. VADåˆ†æ®µ
            std::map<std::string, py::object> vad_cache;
            auto vad_result = DetectVoiceActivity(audio_data, vad_cache);
            
            if (vad_result.HasValidSegments()) {
                Logger::Info("VADæ£€æµ‹åˆ°{}ä¸ªè¯­éŸ³æ®µ", vad_result.segments.size());
                
                // 2. å¯¹æ¯ä¸ªè¯­éŸ³æ®µè¿›è¡ŒASRè¯†åˆ«
                std::vector<std::string> segment_texts;
                for (const auto& segment : vad_result.segments) {
                    int start_sample = (segment.first * 16000) / 1000;  // msè½¬æ¢ä¸ºæ ·æœ¬
                    int end_sample = (segment.second * 16000) / 1000;
                    
                    if (start_sample >= 0 && end_sample <= static_cast<int>(audio_data.size()) && 
                        end_sample > start_sample) {
                        
                        std::vector<float> segment_audio(
                            audio_data.begin() + start_sample,
                            audio_data.begin() + end_sample
                        );
                        
                        // ASRè¯†åˆ«å•ä¸ªæ®µ
                        py::array_t<float> audio_array = VectorToNumpy(segment_audio);
                        py::dict asr_kwargs;
                        asr_kwargs["input"] = audio_array;
                        
                        py::object asr_result = offline_model_.attr("generate")(**asr_kwargs);
                        auto parsed_result = ParseRecognitionResult(asr_result, 0);
                        
                        if (!parsed_result.text.empty()) {
                            segment_texts.push_back(parsed_result.text);
                        }
                    }
                }
                
                // åˆå¹¶æ‰€æœ‰æ®µçš„æ–‡æœ¬
                for (const auto& text : segment_texts) {
                    if (!final_text.empty()) final_text += " ";
                    final_text += text;
                }
            } else {
                Logger::Info("VADæœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³æ®µï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘è¯†åˆ«");
                enable_vad = false;  // å›é€€åˆ°å®Œæ•´éŸ³é¢‘è¯†åˆ«
            }
        }
        
        // å¦‚æœæœªå¯ç”¨VADæˆ–VADæœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘è¯†åˆ«
        if (!enable_vad || final_text.empty()) {
            py::array_t<float> audio_array = VectorToNumpy(audio_data);
            py::dict asr_kwargs;
            asr_kwargs["input"] = audio_array;
            
            py::object asr_result = offline_model_.attr("generate")(**asr_kwargs);
            auto parsed_result = ParseRecognitionResult(asr_result, 0);
            final_text = parsed_result.text;
        }
        
        // 3. æ ‡ç‚¹ç¬¦å·æ¢å¤
        if (enable_punctuation && !final_text.empty()) {
            std::map<std::string, py::object> punc_cache;
            final_text = AddPunctuation(final_text, punc_cache);
        }
        
        result.text = final_text;
        result.is_final = true;
        result.is_offline_result = true;
        result.inference_time_ms = total_timer.ElapsedMs();
        
        // æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        {
            std::lock_guard<std::mutex> lock(metrics_mutex_);
            current_metrics_.total_requests++;
            if (!result.IsEmpty()) {
                current_metrics_.success_requests++;
                double audio_duration_s = audio_data.size() / 16000.0;
                current_metrics_.offline_rtf = result.inference_time_ms / (audio_duration_s * 1000.0);
                current_metrics_.total_audio_processed_hours += audio_duration_s / 3600.0;
            }
        }
        
        Logger::Info("ç¦»çº¿è¯†åˆ«å®Œæˆ: '{}...', è€—æ—¶: {:.1f}ms", 
                    result.text.substr(0, 30), result.inference_time_ms);
        
    } catch (const std::exception& e) {
        Logger::Error("ç¦»çº¿è¯†åˆ«å¼‚å¸¸: {}", e.what());
        current_metrics_.total_requests++;
    }
    
    return result;
}

FunASREngine::RecognitionResult FunASREngine::StreamingRecognize(
    const std::vector<float>& audio_chunk,
    TwoPassSession& session,
    bool is_final) {
    
    RecognitionResult result;
    if (!initialized_) {
        Logger::Error("å¼•æ“æœªåˆå§‹åŒ–");
        return result;
    }
    
    try {
        Timer inference_timer;
        
        // 1. è½¬æ¢éŸ³é¢‘æ•°æ®ä¸ºnumpyæ•°ç»„
        py::array_t<float> audio_array = VectorToNumpy(audio_chunk);
        
        // 2. æ„å»ºæµå¼æ¨ç†å‚æ•° (å¯¹åº”FunASR streaming generateå‚æ•°)
        py::dict kwargs;
        kwargs["input"] = audio_array;
        kwargs["is_final"] = is_final;
        kwargs["chunk_size"] = py::make_tuple(
            session.chunk_size[0], 
            session.chunk_size[1], 
            session.chunk_size[2]
        );
        kwargs["encoder_chunk_look_back"] = session.encoder_chunk_look_back;
        kwargs["decoder_chunk_look_back"] = session.decoder_chunk_look_back;
        
        // 3. æ·»åŠ ç¼“å­˜çŠ¶æ€ (ç»´æŒæµå¼ä¸Šä¸‹æ–‡)
        if (!session.streaming_cache.empty()) {
            py::dict cache_dict;
            for (const auto& item : session.streaming_cache) {
                cache_dict[py::str(item.first)] = item.second;
            }
            kwargs["cache"] = cache_dict;
        }
        
        // 4. æ‰§è¡Œæµå¼æ¨ç†
        py::object py_result = streaming_model_.attr("generate")(**kwargs);
        
        // 5. æ›´æ–°ç¼“å­˜çŠ¶æ€ (é‡è¦ï¼šä¿æŒæµå¼è¿ç»­æ€§) - ä¿®å¤pybind11å¯¹è±¡èµ‹å€¼é—®é¢˜
        if (kwargs.contains("cache")) {
            py::dict updated_cache = kwargs["cache"];
            session.streaming_cache.clear();
            for (auto item : updated_cache) {
                // ä¿®å¤ï¼šä½¿ç”¨reinterpret_borrowæ˜¾å¼è½¬æ¢handleåˆ°object
                session.streaming_cache[item.first.cast<std::string>()] = 
                    py::reinterpret_borrow<py::object>(item.second);
            }
        }
        
        // 6. è§£æç»“æœ
        result = ParseRecognitionResult(py_result, inference_timer.ElapsedMs());
        result.is_final = is_final;
        result.is_online_result = true;
        
        // 7. æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        {
            std::lock_guard<std::mutex> lock(metrics_mutex_);
            current_metrics_.total_requests++;
            if (!result.IsEmpty()) {
                current_metrics_.success_requests++;
                double chunk_duration_s = audio_chunk.size() / 16000.0;
                current_metrics_.streaming_rtf = result.inference_time_ms / (chunk_duration_s * 1000.0);
                current_metrics_.online_latency_ms = result.inference_time_ms;
                current_metrics_.total_audio_processed_hours += chunk_duration_s / 3600.0;
            }
        }
        
        Logger::Info("æµå¼è¯†åˆ«: '{}', è€—æ—¶: {:.1f}ms, RTF: {:.4f}", 
                    result.text, result.inference_time_ms, current_metrics_.streaming_rtf);
                    
    } catch (const std::exception& e) {
        Logger::Error("æµå¼è¯†åˆ«å¼‚å¸¸: {}", e.what());
        current_metrics_.total_requests++;
    }
    
    return result;
}

void FunASREngine::TwoPassRecognize(
    const std::vector<float>& audio_chunk,
    TwoPassSession& session,
    std::vector<RecognitionResult>& results) {
    
    if (!initialized_) {
        Logger::Error("å¼•æ“æœªåˆå§‹åŒ–");
        return;
    }
    
    try {
        Timer total_timer;
        
        // æ·»åŠ éŸ³é¢‘å—åˆ°ç¼“å†²åŒº
        session.audio_buffer.insert(session.audio_buffer.end(), 
                                   audio_chunk.begin(), audio_chunk.end());
        
        // 1. å¹¶è¡Œæ‰§è¡ŒVADæ£€æµ‹å’Œæµå¼è¯†åˆ«
        std::future<VADResult> vad_future = std::async(std::launch::async, [this, &audio_chunk, &session]() {
            return DetectVoiceActivity(audio_chunk, session.vad_cache);
        });
        
        std::future<RecognitionResult> streaming_future = std::async(std::launch::async, 
            [this, &audio_chunk, &session]() {
            return StreamingRecognize(audio_chunk, session, false);
        });
        
        // 2. è·å–æµå¼è¯†åˆ«ç»“æœ (ç«‹å³è¿”å›ç»™ç”¨æˆ·)
        auto streaming_result = streaming_future.get();
        if (!streaming_result.IsEmpty()) {
            streaming_result.is_online_result = true;
            results.push_back(streaming_result);
        }
        
        // 3. å¤„ç†VADç»“æœ
        auto vad_result = vad_future.get();
        current_metrics_.vad_processing_ms = vad_result.inference_time_ms;
        
        // 4. æ£€æµ‹è¯­éŸ³ç»“æŸç‚¹
        if (vad_result.speech_end_ms != -1) {
            session.is_speaking = false;
            
            // è§¦å‘ç¦»çº¿ç²¾åŒ–è¯†åˆ«
            Logger::Info("æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œå¯åŠ¨ç¦»çº¿ç²¾åŒ–å¤„ç†");
            
            // æå–å®Œæ•´è¯­éŸ³æ®µè¿›è¡Œç¦»çº¿è¯†åˆ«
            std::vector<float> complete_segment = session.audio_buffer;
            
            // å¼‚æ­¥æ‰§è¡Œç¦»çº¿ç²¾åŒ– (é¿å…é˜»å¡å®æ—¶æµ)
            std::thread([this, complete_segment, &session, &results]() {
                Timer offline_timer;
                
                auto offline_result = OfflineRecognize(complete_segment, false, true);
                if (!offline_result.IsEmpty()) {
                    offline_result.is_offline_result = true;
                    offline_result.is_final = true;
                    
                    // è®¡ç®—ç¦»çº¿ç²¾åŒ–æ—¶é—´
                    current_metrics_.offline_refinement_ms = offline_timer.ElapsedMs();
                    
                    // æ³¨æ„: åœ¨å®é™…åº”ç”¨ä¸­ï¼Œéœ€è¦é€šè¿‡å›è°ƒæˆ–é˜Ÿåˆ—æœºåˆ¶è¿”å›ç»“æœ
                    Logger::Info("ç¦»çº¿ç²¾åŒ–å®Œæˆ: '{}'", offline_result.text);
                }
                
                // é‡ç½®ä¼šè¯çŠ¶æ€
                session.Reset();
                
            }).detach();
        } else if (vad_result.speech_start_ms != -1) {
            session.is_speaking = true;
        }
        
        // æ›´æ–°2Passæ¨¡å¼æ€§èƒ½æŒ‡æ ‡
        {
            std::lock_guard<std::mutex> lock(metrics_mutex_);
            double chunk_duration_s = audio_chunk.size() / 16000.0;
            current_metrics_.two_pass_rtf = total_timer.ElapsedMs() / (chunk_duration_s * 1000.0);
            current_metrics_.end_to_end_latency_ms = total_timer.ElapsedMs();
        }
        
    } catch (const std::exception& e) {
        Logger::Error("2Passè¯†åˆ«å¼‚å¸¸: {}", e.what());
    }
}

FunASREngine::VADResult FunASREngine::DetectVoiceActivity(
    const std::vector<float>& audio_data,
    std::map<std::string, py::object>& vad_cache,
    int max_single_segment_time) {
    
    VADResult result;
    
    try {
        Timer vad_timer;
        
        // è½¬æ¢éŸ³é¢‘æ•°æ®
        py::array_t<float> audio_array = VectorToNumpy(audio_data);
        
        // æ„å»ºVADå‚æ•° (å¯¹åº”FunASR VAD generateå‚æ•°)
        py::dict kwargs;
        kwargs["input"] = audio_array;
        kwargs["max_single_segment_time"] = max_single_segment_time;
        
        // æ·»åŠ ç¼“å­˜çŠ¶æ€
        if (!vad_cache.empty()) {
            py::dict cache_dict;
            for (const auto& item : vad_cache) {
                cache_dict[py::str(item.first)] = item.second;
            }
            kwargs["cache"] = cache_dict;
        }
        
        // æ‰§è¡ŒVADæ¨ç†
        py::object vad_py_result = vad_model_.attr("generate")(**kwargs);
        
        // æ›´æ–°ç¼“å­˜ - ä¿®å¤pybind11å¯¹è±¡èµ‹å€¼é—®é¢˜
        if (kwargs.contains("cache")) {
            py::dict updated_cache = kwargs["cache"];
            vad_cache.clear();
            for (auto item : updated_cache) {
                // ä¿®å¤ï¼šä½¿ç”¨reinterpret_borrowæ˜¾å¼è½¬æ¢
                vad_cache[item.first.cast<std::string>()] = 
                    py::reinterpret_borrow<py::object>(item.second);
            }
        }
        
        result = ParseVADResult(vad_py_result, vad_timer.ElapsedMs());
        
    } catch (const std::exception& e) {
        Logger::Error("VADæ£€æµ‹å¼‚å¸¸: {}", e.what());
    }
    
    return result;
}

std::string FunASREngine::AddPunctuation(const std::string& text, 
                                         std::map<std::string, py::object>& punc_cache) {
    if (text.empty() || punc_model_.is_none()) {
        return text;
    }
    
    try {
        Timer punc_timer;
        
        // æ„å»ºæ ‡ç‚¹ç¬¦å·æ¢å¤å‚æ•°
        py::dict kwargs;
        kwargs["input"] = text;
        
        // æ·»åŠ ç¼“å­˜çŠ¶æ€
        if (!punc_cache.empty()) {
            py::dict cache_dict;
            for (const auto& item : punc_cache) {
                cache_dict[py::str(item.first)] = item.second;
            }
            kwargs["cache"] = cache_dict;
        }
        
        // æ‰§è¡Œæ ‡ç‚¹ç¬¦å·æ¢å¤
        py::object punc_result = punc_model_.attr("generate")(**kwargs);
        
        // æ›´æ–°ç¼“å­˜ - ä¿®å¤pybind11å¯¹è±¡èµ‹å€¼é—®é¢˜
        if (kwargs.contains("cache")) {
            py::dict updated_cache = kwargs["cache"];
            punc_cache.clear();
            for (auto item : updated_cache) {
                // ä¿®å¤ï¼šä½¿ç”¨reinterpret_borrowæ˜¾å¼è½¬æ¢
                punc_cache[item.first.cast<std::string>()] = 
                    py::reinterpret_borrow<py::object>(item.second);
            }
        }
        
        // è§£æç»“æœ
        if (py::isinstance<py::list>(punc_result)) {
            py::list result_list = punc_result;
            if (result_list.size() > 0) {
                py::dict first_result = result_list[0];
                if (first_result.contains("text")) {
                    std::string punctuated_text = first_result["text"].cast<std::string>();
                    
                    // æ›´æ–°æ ‡ç‚¹ç¬¦å·å¤„ç†æ—¶é—´
                    current_metrics_.punctuation_ms = punc_timer.ElapsedMs();
                    
                    return punctuated_text;
                }
            }
        }
        
    } catch (const std::exception& e) {
        Logger::Error("æ ‡ç‚¹ç¬¦å·å¤„ç†å¼‚å¸¸: {}", e.what());
    }
    
    return text;  // å‡ºé”™æ—¶è¿”å›åŸæ–‡æœ¬
}

// ============ è¾…åŠ©æ–¹æ³•å®ç° ============

py::array_t<float> FunASREngine::VectorToNumpy(const std::vector<float>& data) {
    return py::array_t<float>(
        data.size(), 
        data.data(), 
        py::cast(this)
    );
}

FunASREngine::RecognitionResult FunASREngine::ParseRecognitionResult(
    const py::object& result, double inference_time_ms) {
    
    RecognitionResult parsed;
    parsed.inference_time_ms = inference_time_ms;
    
    try {
        if (py::isinstance<py::list>(result)) {
            py::list result_list = result;
            if (result_list.size() > 0) {
                py::dict first_result = result_list[0];
                if (first_result.contains("text")) {
                    parsed.text = first_result["text"].cast<std::string>();
                }
            }
        }
    } catch (const std::exception& e) {
        Logger::Error("è¯†åˆ«ç»“æœè§£æå¼‚å¸¸: {}", e.what());
    }
    
    return parsed;
}

FunASREngine::VADResult FunASREngine::ParseVADResult(
    const py::object& result, double inference_time_ms) {
    
    VADResult parsed;
    parsed.inference_time_ms = inference_time_ms;
    
    try {
        if (py::isinstance<py::list>(result)) {
            py::list result_list = result;
            if (result_list.size() > 0) {
                py::dict first_result = result_list[0];
                if (first_result.contains("value")) {
                    py::list segments = first_result["value"];
                    
                    for (auto segment : segments) {
                        // ä¿®å¤ï¼šæ˜¾å¼è½¬æ¢handleåˆ°list
                        py::list seg_pair = py::reinterpret_borrow<py::list>(segment);
                        if (seg_pair.size() >= 2) {
                            int64_t start = seg_pair[0].cast<int64_t>();
                            int64_t end = seg_pair[1].cast<int64_t>();
                            
                            parsed.segments.emplace_back(start, end);
                            
                            if (start != -1 && parsed.speech_start_ms == -1) {
                                parsed.speech_start_ms = start;
                            }
                            if (end != -1) {
                                parsed.speech_end_ms = end;
                            }
                        }
                    }
                    
                    parsed.has_speech = !parsed.segments.empty();
                }
            }
        }
    } catch (const std::exception& e) {
        Logger::Error("VADç»“æœè§£æå¼‚å¸¸: {}", e.what());
    }
    
    return parsed;
}

double FunASREngine::GetGPUMemoryUsage() {
    try {
        py::module_ torch = py::module_::import("torch");
        if (torch.attr("cuda").attr("is_available")().cast<bool>()) {
            py::object memory_allocated = torch.attr("cuda").attr("memory_allocated")(0);
            return memory_allocated.cast<size_t>() / (1024.0 * 1024.0 * 1024.0);
        }
    } catch (...) {
        // é™é»˜å¤„ç†å¼‚å¸¸
    }
    return 0.0;
}

// ============ æ€§èƒ½æµ‹è¯•å®ç° ============

bool FunASREngine::RunPerformanceTests() {
    if (!initialized_ || test_audio_files_.empty()) {
        Logger::Error("å¼•æ“æœªåˆå§‹åŒ–æˆ–æ— æµ‹è¯•æ–‡ä»¶");
        return false;
    }
    
    Logger::Info("ğŸ§ª å¼€å§‹FunASR GPUå®Œæ•´æ€§èƒ½æµ‹è¯•å¥—ä»¶...");
    Logger::Info("æµ‹è¯•æ–‡ä»¶æ•°: {}, GPUè®¾å¤‡: {}", test_audio_files_.size(), config_.device);
    
    testing_active_ = true;
    
    // åœ¨åå°çº¿ç¨‹è¿è¡Œæµ‹è¯•
    test_thread_ = std::thread([this]() {
        try {
            Timer total_test_timer;
            
            // 1. ç¦»çº¿è¯†åˆ«æ€§èƒ½æµ‹è¯•
            if (config_.enable_offline_test) {
                Logger::Info("1ï¸âƒ£ ç¦»çº¿è¯†åˆ«æ€§èƒ½æµ‹è¯•...");
                auto offline_metrics = TestOfflinePerformance();
                UpdateMetrics(offline_metrics);
            }
            
            // 2. æµå¼è¯†åˆ«æ€§èƒ½æµ‹è¯•
            if (config_.enable_streaming_test) {
                Logger::Info("2ï¸âƒ£ æµå¼è¯†åˆ«æ€§èƒ½æµ‹è¯•...");
                auto streaming_metrics = TestStreamingPerformance();
                UpdateMetrics(streaming_metrics);
            }
            
            // 3. 2Passæ¨¡å¼æ€§èƒ½æµ‹è¯•
            if (config_.enable_two_pass_test) {
                Logger::Info("3ï¸âƒ£ 2Passæ¨¡å¼æ€§èƒ½æµ‹è¯•...");
                auto two_pass_metrics = TestTwoPassPerformance();
                UpdateMetrics(two_pass_metrics);
            }
            
            // 4. å¹¶å‘æ€§èƒ½æµ‹è¯•
            if (config_.enable_concurrent_test) {
                Logger::Info("4ï¸âƒ£ å¹¶å‘æ€§èƒ½æµ‹è¯•...");
                auto concurrent_metrics = TestConcurrentPerformance();
                UpdateMetrics(concurrent_metrics);
            }
            
            Logger::Info("ğŸ‰ å®Œæ•´æ€§èƒ½æµ‹è¯•å¥—ä»¶å®Œæˆï¼æ€»è€—æ—¶: {:.1f}ç§’", total_test_timer.ElapsedMs() / 1000.0);
            
        } catch (const std::exception& e) {
            Logger::Error("æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {}", e.what());
        }
        
        testing_active_ = false;
    });
    
    return true;
}

PerformanceMetrics FunASREngine::TestOfflinePerformance() {
    PerformanceMetrics metrics;
    
    // é€‰æ‹©å‰20ä¸ªæ–‡ä»¶è¿›è¡Œç¦»çº¿æµ‹è¯•
    int test_count = std::min(20, static_cast<int>(test_audio_files_.size()));
    std::vector<double> rtf_values;
    double total_audio_duration = 0.0;
    
    Logger::Info("ç¦»çº¿æµ‹è¯•ä½¿ç”¨{}ä¸ªéŸ³é¢‘æ–‡ä»¶", test_count);
    
    for (int i = 0; i < test_count; ++i) {
        const auto& file_path = test_audio_files_[i];
        
        // è¯»å–éŸ³é¢‘æ–‡ä»¶
        auto audio_data = AudioFileReader::ReadWavFile(file_path);
        if (!audio_data.IsValid()) {
            Logger::Warn("è·³è¿‡æ— æ•ˆéŸ³é¢‘æ–‡ä»¶: {}", file_path);
            continue;
        }
        
        // æ‰§è¡Œç¦»çº¿è¯†åˆ«
        Timer test_timer;
        auto result = OfflineRecognize(audio_data.samples, true, true);
        double elapsed_ms = test_timer.ElapsedMs();
        
        if (!result.IsEmpty()) {
            double rtf = elapsed_ms / (audio_data.duration_seconds * 1000.0);
            rtf_values.push_back(rtf);
            total_audio_duration += audio_data.duration_seconds;
            
            Logger::Info("ç¦»çº¿æµ‹è¯• [{}/{}]: {:.1f}ç§’éŸ³é¢‘, RTF={:.4f}, ç»“æœ: '{}'", 
                        i+1, test_count, audio_data.duration_seconds, rtf, 
                        result.text.substr(0, 30));
        }
    }
    
    // è®¡ç®—å¹³å‡RTF
    if (!rtf_values.empty()) {
        double sum = 0;
        for (double rtf : rtf_values) sum += rtf;
        metrics.offline_rtf = sum / rtf_values.size();
        metrics.total_audio_processed_hours = total_audio_duration / 3600.0;
        metrics.test_files_count = rtf_values.size();
    }
    
    Logger::Info("ç¦»çº¿æµ‹è¯•å®Œæˆ: å¹³å‡RTF={:.4f}, å¤„ç†éŸ³é¢‘={:.2f}å°æ—¶", 
                metrics.offline_rtf, metrics.total_audio_processed_hours);
    
    return metrics;
}

PerformanceMetrics FunASREngine::TestStreamingPerformance() {
    PerformanceMetrics metrics;
    
    // é€‰æ‹©å‰15ä¸ªæ–‡ä»¶è¿›è¡Œæµå¼æµ‹è¯•
    int test_count = std::min(15, static_cast<int>(test_audio_files_.size()));
    std::vector<double> rtf_values;
    std::vector<double> latency_values;
    
    Logger::Info("æµå¼æµ‹è¯•ä½¿ç”¨{}ä¸ªéŸ³é¢‘æ–‡ä»¶", test_count);
    
    for (int i = 0; i < test_count; ++i) {
        const auto& file_path = test_audio_files_[i];
        
        auto audio_data = AudioFileReader::ReadWavFile(file_path);
        if (!audio_data.IsValid()) continue;
        
        // æ¨¡æ‹Ÿæµå¼å¤„ç†ï¼šå°†éŸ³é¢‘åˆ†æˆ600msçš„å—
        auto chunks = SimulateStreamingChunks(audio_data.samples);
        TwoPassSession session;
        
        for (size_t chunk_idx = 0; chunk_idx < chunks.size(); ++chunk_idx) {
            bool is_final = (chunk_idx == chunks.size() - 1);
            auto result = StreamingRecognize(chunks[chunk_idx], session, is_final);
            
            if (!result.IsEmpty()) {
                double chunk_duration_ms = chunks[chunk_idx].size() / 16.0;  // 16kHz
                double rtf = result.inference_time_ms / chunk_duration_ms;
                rtf_values.push_back(rtf);
                latency_values.push_back(result.inference_time_ms);
            }
        }
        
        Logger::Info("æµå¼æµ‹è¯• [{}/{}]: {:.1f}ç§’éŸ³é¢‘, {}ä¸ªåˆ†å—", 
                    i+1, test_count, audio_data.duration_seconds, chunks.size());
    }
    
    // è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    if (!rtf_values.empty()) {
        double sum_rtf = 0, sum_latency = 0;
        for (double rtf : rtf_values) sum_rtf += rtf;
        for (double lat : latency_values) sum_latency += lat;
        
        metrics.streaming_rtf = sum_rtf / rtf_values.size();
        metrics.online_latency_ms = sum_latency / latency_values.size();
        metrics.end_to_end_latency_ms = metrics.online_latency_ms;
    }
    
    Logger::Info("æµå¼æµ‹è¯•å®Œæˆ: å¹³å‡RTF={:.4f}, å¹³å‡å»¶è¿Ÿ={:.1f}ms", 
                metrics.streaming_rtf, metrics.online_latency_ms);
    
    return metrics;
}

PerformanceMetrics FunASREngine::TestTwoPassPerformance() {
    PerformanceMetrics metrics;
    
    // é€‰æ‹©10ä¸ªæ–‡ä»¶è¿›è¡Œ2Passæµ‹è¯•
    int test_count = std::min(10, static_cast<int>(test_audio_files_.size()));
    std::vector<double> rtf_values;
    
    Logger::Info("2Passæµ‹è¯•ä½¿ç”¨{}ä¸ªéŸ³é¢‘æ–‡ä»¶", test_count);
    
    for (int i = 0; i < test_count; ++i) {
        const auto& file_path = test_audio_files_[i];
        
        auto audio_data = AudioFileReader::ReadWavFile(file_path);
        if (!audio_data.IsValid()) continue;
        
        // æ¨¡æ‹Ÿ2Passå¤„ç†
        auto chunks = SimulateStreamingChunks(audio_data.samples);
        TwoPassSession session;
        std::vector<RecognitionResult> results;
        
        Timer two_pass_timer;
        
        for (size_t chunk_idx = 0; chunk_idx < chunks.size(); ++chunk_idx) {
            TwoPassRecognize(chunks[chunk_idx], session, results);
        }
        
        double elapsed_ms = two_pass_timer.ElapsedMs();
        double rtf = elapsed_ms / (audio_data.duration_seconds * 1000.0);
        rtf_values.push_back(rtf);
        
        Logger::Info("2Passæµ‹è¯• [{}/{}]: {:.1f}ç§’éŸ³é¢‘, RTF={:.4f}, è¾“å‡º{}ä¸ªç»“æœ", 
                    i+1, test_count, audio_data.duration_seconds, rtf, results.size());
    }
    
    // è®¡ç®—å¹³å‡RTF
    if (!rtf_values.empty()) {
        double sum = 0;
        for (double rtf : rtf_values) sum += rtf;
        metrics.two_pass_rtf = sum / rtf_values.size();
    }
    
    Logger::Info("2Passæµ‹è¯•å®Œæˆ: å¹³å‡RTF={:.4f}", metrics.two_pass_rtf);
    
    return metrics;
}

PerformanceMetrics FunASREngine::TestConcurrentPerformance() {
    PerformanceMetrics metrics;
    
    const int num_workers = config_.max_concurrent_sessions;
    const int files_per_worker = std::max(1, static_cast<int>(test_audio_files_.size()) / num_workers);
    
    Logger::Info("å¯åŠ¨{}è·¯å¹¶å‘æµ‹è¯•ï¼Œæ¯è·¯å¤„ç†{}ä¸ªæ–‡ä»¶", num_workers, files_per_worker);
    
    std::vector<std::future<void>> futures;
    std::vector<PerformanceMetrics> worker_results(num_workers);
    std::atomic<int> active_sessions{0};
    
    Timer concurrent_timer;
    
    // å¯åŠ¨å¹¶å‘å·¥ä½œçº¿ç¨‹
    for (int i = 0; i < num_workers; ++i) {
        int start_idx = i * files_per_worker;
        int end_idx = std::min(start_idx + files_per_worker, static_cast<int>(test_audio_files_.size()));
        
        std::vector<std::string> worker_files(
            test_audio_files_.begin() + start_idx,
            test_audio_files_.begin() + end_idx
        );
        
        futures.emplace_back(std::async(std::launch::async, [this, i, worker_files, &active_sessions, &worker_results]() {
            ConcurrentTestWorker(i, worker_files, active_sessions, worker_results);
        }));
    }
    
    // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for (auto& future : futures) {
        future.wait();
    }
    
    double total_time_s = concurrent_timer.ElapsedMs() / 1000.0;
    
    // èšåˆç»“æœ
    double total_rtf = 0;
    int valid_results = 0;
    
    for (const auto& result : worker_results) {
        if (result.streaming_rtf > 0) {
            total_rtf += result.streaming_rtf;
            valid_results++;
        }
    }
    
    if (valid_results > 0) {
        metrics.streaming_rtf = total_rtf / valid_results;
    }
    metrics.concurrent_sessions = num_workers;
    
    Logger::Info("å¹¶å‘æµ‹è¯•å®Œæˆ: {}è·¯å¹¶å‘, å¹³å‡RTF={:.4f}, æ€»è€—æ—¶={:.1f}ç§’", 
                num_workers, metrics.streaming_rtf, total_time_s);
    
    return metrics;
}

void FunASREngine::ConcurrentTestWorker(
    int worker_id,
    const std::vector<std::string>& worker_files,
    std::atomic<int>& active_sessions,
    std::vector<PerformanceMetrics>& results) {
    
    try {
        active_sessions++;
        
        PerformanceMetrics worker_metrics;
        std::vector<double> rtf_values;
        
        for (const auto& file_path : worker_files) {
            auto audio_data = AudioFileReader::ReadWavFile(file_path);
            if (!audio_data.IsValid()) continue;
            
            // æ‰§è¡Œæµå¼è¯†åˆ«æµ‹è¯•
            auto chunks = SimulateStreamingChunks(audio_data.samples);
            TwoPassSession session;
            
            Timer worker_timer;
            for (const auto& chunk : chunks) {
                auto result = StreamingRecognize(chunk, session, false);
            }
            double elapsed_ms = worker_timer.ElapsedMs();
            
            double rtf = elapsed_ms / (audio_data.duration_seconds * 1000.0);
            rtf_values.push_back(rtf);
        }
        
        // è®¡ç®—è¯¥workerçš„å¹³å‡RTF
        if (!rtf_values.empty()) {
            double sum = 0;
            for (double rtf : rtf_values) sum += rtf;
            worker_metrics.streaming_rtf = sum / rtf_values.size();
        }
        
        results[worker_id] = worker_metrics;
        active_sessions--;
        
        Logger::Info("å¹¶å‘Worker-{} å®Œæˆ: å¤„ç†{}ä¸ªæ–‡ä»¶, å¹³å‡RTF={:.4f}", 
                    worker_id, worker_files.size(), worker_metrics.streaming_rtf);
        
    } catch (const std::exception& e) {
        Logger::Error("å¹¶å‘Worker-{} å¼‚å¸¸: {}", worker_id, e.what());
        active_sessions--;
    }
}

std::vector<std::vector<float>> FunASREngine::SimulateStreamingChunks(
    const std::vector<float>& audio_data, double chunk_duration_ms) {
    
    std::vector<std::vector<float>> chunks;
    const int chunk_samples = static_cast<int>((chunk_duration_ms / 1000.0) * 16000);  // 16kHz
    
    for (size_t i = 0; i < audio_data.size(); i += chunk_samples) {
        size_t end_idx = std::min(i + chunk_samples, audio_data.size());
        chunks.emplace_back(audio_data.begin() + i, audio_data.begin() + end_idx);
    }
    
    return chunks;
}

PerformanceMetrics FunASREngine::GetPerformanceMetrics() const {
    std::lock_guard<std::mutex> lock(metrics_mutex_);
    auto metrics = current_metrics_;
    metrics.gpu_memory_gb = const_cast<FunASREngine*>(this)->GetGPUMemoryUsage();
    return metrics;
}

void FunASREngine::UpdateMetrics(const PerformanceMetrics& new_metrics) {
    std::lock_guard<std::mutex> lock(metrics_mutex_);
    
    // æ›´æ–°éé›¶å€¼
    if (new_metrics.streaming_rtf > 0) {
        current_metrics_.streaming_rtf = new_metrics.streaming_rtf;
    }
    if (new_metrics.offline_rtf > 0) {
        current_metrics_.offline_rtf = new_metrics.offline_rtf;
    }
    if (new_metrics.two_pass_rtf > 0) {
        current_metrics_.two_pass_rtf = new_metrics.two_pass_rtf;
    }
    if (new_metrics.end_to_end_latency_ms > 0) {
        current_metrics_.end_to_end_latency_ms = new_metrics.end_to_end_latency_ms;
    }
    if (new_metrics.online_latency_ms > 0) {
        current_metrics_.online_latency_ms = new_metrics.online_latency_ms;
    }
    if (new_metrics.concurrent_sessions > 0) {
        current_metrics_.concurrent_sessions = new_metrics.concurrent_sessions;
    }
    if (new_metrics.total_audio_processed_hours > 0) {
        current_metrics_.total_audio_processed_hours += new_metrics.total_audio_processed_hours;
    }
    if (new_metrics.test_files_count > 0) {
        current_metrics_.test_files_count = new_metrics.test_files_count;
    }
    
    current_metrics_.gpu_memory_gb = new_metrics.gpu_memory_gb;
}
