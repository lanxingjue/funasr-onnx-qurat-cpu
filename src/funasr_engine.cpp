#include "funasr_engine.h"
#include <random>
#include <algorithm>
#include <future>
#include <sstream>
#include <iomanip>

// Linuxç³»ç»Ÿç›¸å…³å¤´æ–‡ä»¶ (CPUç‰ˆæœ¬æ–°å¢)
#ifdef __linux__
#include <sys/resource.h>  // CPUèµ„æºç›‘æ§
#include <unistd.h>        // ç³»ç»Ÿä¿¡æ¯
#endif

/**
 * æ„é€ å‡½æ•° - CPUç‰ˆæœ¬é€‚é…
 * 
 * ğŸ”„ ä¸»è¦å˜åŒ–: æ—¥å¿—è¾“å‡ºé€‚é…CPUæ¨¡å¼
 */
FunASREngine::FunASREngine(const Config& config) : config_(config) {
    // ä¿®å¤æ—¥å¿—æ ¼å¼åŒ–é—®é¢˜ - ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥æ›¿ä»£æ¨¡æ¿æ ¼å¼åŒ–
    std::ostringstream log_msg;
    log_msg << "åˆ›å»ºFunASR CPUå¼•æ“ï¼Œè®¾å¤‡: " << config_.device 
            << ", éŸ³é¢‘ç›®å½•: " << config_.audio_files_dir;
    Logger::Info(log_msg.str());
    
    // CPUç‰¹æœ‰ä¿¡æ¯æ—¥å¿—
    std::ostringstream cpu_info;
    cpu_info << "CPUé…ç½®: " << config_.cpu_threads << "æ ¸å¿ƒ, "
             << "æœ€å¤§å¹¶å‘: " << config_.max_concurrent_sessions << "è·¯";
    Logger::Info(cpu_info.str());
}

FunASREngine::~FunASREngine() {
    testing_active_ = false;
    if (test_thread_.joinable()) {
        test_thread_.join();
    }
    Logger::Info("FunASR CPUå¼•æ“å·²é”€æ¯");
}

/**
 * åˆå§‹åŒ–å¼•æ“ - CPUç‰ˆæœ¬æ ¸å¿ƒæ”¹é€ 
 * 
 * ğŸ”„ ä¸»è¦æ”¹é€ ç‚¹:
 * 1. å¢åŠ CPUæ€§èƒ½ä¼˜åŒ–æ­¥éª¤
 * 2. ä¿®æ”¹Pythonç¯å¢ƒåˆå§‹åŒ– (CPUæ¨¡å¼)
 * 3. ä¿®æ”¹èµ„æºç›‘æ§ (CPUå†…å­˜æ›¿ä»£GPUæ˜¾å­˜)
 * 4. ä¿®å¤æ—¥å¿—æ ¼å¼åŒ–é—®é¢˜
 */
bool FunASREngine::Initialize() {
    Logger::Info("åˆå§‹åŒ–FunASR CPUå¼•æ“...");
    Timer init_timer;
    
    try {
        // 1. CPUæ€§èƒ½ä¼˜åŒ– (ğŸ†• CPUç‰ˆæœ¬æ–°å¢)
        if (config_.enable_cpu_optimization) {
            OptimizeCPUPerformance();
        }
        
        // 2. åˆå§‹åŒ–Pythonç¯å¢ƒ - CPUæ¨¡å¼é€‚é…
        if (!InitializePython()) {
            Logger::Error("Pythonç¯å¢ƒåˆå§‹åŒ–å¤±è´¥");
            return false;
        }
        
        // 3. åŠ è½½æ‰€æœ‰FunASRæ¨¡å‹ - CPUé…ç½®
        Logger::Info("åŠ è½½FunASRæ¨¡å‹ç»„ä»¶åˆ°CPU...");
        
        // åŠ è½½æµå¼ASRæ¨¡å‹
        if (!LoadFunASRModel("streaming_asr", config_.streaming_model,
                            config_.streaming_revision, streaming_model_)) {
            Logger::Error("æµå¼ASRæ¨¡å‹åŠ è½½å¤±è´¥");
            return false;
        }
        
        // åŠ è½½ç¦»çº¿ASRæ¨¡å‹
        if (!LoadFunASRModel("offline_asr", config_.offline_model,
                            config_.offline_revision, offline_model_)) {
            Logger::Error("ç¦»çº¿ASRæ¨¡å‹åŠ è½½å¤±è´¥");
            return false;
        }
        
        // åŠ è½½VADæ¨¡å‹
        if (!LoadFunASRModel("vad", config_.vad_model,
                            config_.vad_revision, vad_model_)) {
            Logger::Error("VADæ¨¡å‹åŠ è½½å¤±è´¥");
            return false;
        }
        
        // åŠ è½½æ ‡ç‚¹ç¬¦å·æ¨¡å‹
        if (!LoadFunASRModel("punctuation", config_.punc_model,
                            config_.punc_revision, punc_model_)) {
            Logger::Error("æ ‡ç‚¹ç¬¦å·æ¨¡å‹åŠ è½½å¤±è´¥");
            return false;
        }
        
        // 4. æ£€æŸ¥CPUèµ„æºçŠ¶æ€ (ğŸ”„ æ›¿ä»£GPUçŠ¶æ€æ£€æŸ¥)
        double cpu_memory = GetCPUMemoryUsage();
        std::ostringstream memory_log;
        memory_log << "ç³»ç»Ÿå†…å­˜ä½¿ç”¨: " << std::fixed << std::setprecision(1) << cpu_memory << "GB";
        Logger::Info(memory_log.str());
        
        // 5. åŠ è½½æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
        if (!LoadTestAudioFiles()) {
            Logger::Error("åŠ è½½æµ‹è¯•éŸ³é¢‘æ–‡ä»¶å¤±è´¥");
            return false;
        }
        
        // 6. åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡
        current_metrics_.gpu_memory_gb = cpu_memory;  // å¤ç”¨å­—æ®µå­˜å‚¨CPUå†…å­˜
        current_metrics_.test_files_count = test_audio_files_.size();
        
        initialized_ = true;
        
        // ä¿®å¤æ—¥å¿—æ ¼å¼åŒ– - ä½¿ç”¨ostringstream
        std::ostringstream completion_log;
        completion_log << "FunASR CPUå¼•æ“åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: " 
                      << std::fixed << std::setprecision(1) << init_timer.ElapsedMs() << "ms";
        Logger::Info(completion_log.str());
        
        Logger::Info("å·²åŠ è½½æ¨¡å‹: æµå¼ASR + ç¦»çº¿ASR + VAD + æ ‡ç‚¹ç¬¦å· (CPUæ¨¡å¼)");
        
        std::ostringstream files_log;
        files_log << "æµ‹è¯•éŸ³é¢‘æ–‡ä»¶: " << test_audio_files_.size() << "ä¸ª";
        Logger::Info(files_log.str());
        
        return true;
        
    } catch (const std::exception& e) {
        std::string error_msg = "å¼•æ“åˆå§‹åŒ–å¼‚å¸¸: " + std::string(e.what());
        Logger::Error(error_msg);
        return false;
    }
}


/**
 * åˆå§‹åŒ–Pythonç¯å¢ƒ - CPUæ¨¡å¼æ ¸å¿ƒé€‚é…
 * 
 * ğŸ”„ ä¸»è¦æ”¹é€ ç‚¹:
 * 1. è·³è¿‡CUDAå¯ç”¨æ€§æ£€æŸ¥
 * 2. å¼ºåˆ¶ä½¿ç”¨CPUæ¨¡å¼
 * 3. è®¾ç½®PyTorch CPUçº¿ç¨‹æ•°
 * 4. å¤„ç†CUDAè­¦å‘Š
 */
bool FunASREngine::InitializePython() {
    try {
        // åˆ›å»ºPythonè§£é‡Šå™¨ï¼ˆä¿æŒä¸å˜ï¼‰
        py_guard_ = std::make_unique<py::scoped_interpreter>();
        
        // å¯¼å…¥å¿…è¦æ¨¡å—
        py::module_ sys = py::module_::import("sys");
        py::module_ funasr = py::module_::import("funasr");
        py::module_ torch = py::module_::import("torch");
        
        // ğŸ”„ CPUæ¨¡å¼ - è·³è¿‡CUDAæ£€æŸ¥
        // åŸGPUç‰ˆæœ¬ä¼šæ£€æŸ¥CUDAå¯ç”¨æ€§å¹¶æŠ¥é”™ï¼ŒCPUç‰ˆæœ¬è·³è¿‡
        Logger::Info("Pythonç¯å¢ƒåˆå§‹åŒ–æˆåŠŸ (CPUæ¨¡å¼)");
        
        // ğŸ”„ è®¾ç½®PyTorchä½¿ç”¨CPU
        torch.attr("set_num_threads")(config_.cpu_threads);
        
        // ğŸ”„ å¤„ç†CUDAæ£€æµ‹ä½†å¼ºåˆ¶CPUæ¨¡å¼
        if (torch.attr("cuda").attr("is_available")().cast<bool>()) {
            Logger::Info("æ£€æµ‹åˆ°CUDAï¼Œä½†å¼ºåˆ¶ä½¿ç”¨CPUæ¨¡å¼");
        }
        
        std::ostringstream threads_log;
        threads_log << "PyTorch CPUçº¿ç¨‹æ•°: " << config_.cpu_threads;
        Logger::Info(threads_log.str());
        
        return true;
        
    } catch (const py::error_already_set& e) {
        std::string error_msg = "Pythonåˆå§‹åŒ–å¤±è´¥: " + std::string(e.what());
        Logger::Error(error_msg);
        return false;
    }
}

/**
 * åŠ è½½FunASRæ¨¡å‹ - CPUé…ç½®æ ¸å¿ƒé€‚é…
 * 
 * ğŸ”„ ä¸»è¦æ”¹é€ ç‚¹:
 * 1. device = "cpu" (æ›¿ä»£cudaè®¾å¤‡)
 * 2. ngpu = 0 (ä¸ä½¿ç”¨GPU)
 * 3. ncpu = config_.cpu_threads (ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ)
 * 4. å¢åŠ disable_update=true (å‡å°‘ç½‘ç»œä¾èµ–)
 */
bool FunASREngine::LoadFunASRModel(const std::string& model_type,
                                   const std::string& model_name,
                                   const std::string& model_revision,
                                   py::object& model_obj) {
    try {
        std::ostringstream load_log;
        load_log << "åŠ è½½" << model_type << "æ¨¡å‹åˆ°CPU: " << model_name 
                 << " (ç‰ˆæœ¬: " << model_revision << ")";
        Logger::Info(load_log.str());
        
        Timer load_timer;
        
        // ä½¿ç”¨FunASRçš„AutoModelç±» (ä¿æŒä¸å˜)
        py::module_ funasr = py::module_::import("funasr");
        py::object auto_model = funasr.attr("AutoModel");
        
        // ğŸ”„ CPUæ¨¡å¼é…ç½®å‚æ•° (æ ¸å¿ƒæ”¹é€ )
        py::dict kwargs;
        kwargs["model"] = model_name;
        kwargs["model_revision"] = model_revision;
        kwargs["device"] = config_.device;              // ğŸ”„ "cpu" æ›¿ä»£ "cuda:0"
        kwargs["ngpu"] = 0;                            // ğŸ”„ 0 æ›¿ä»£ 1 (ä¸ä½¿ç”¨GPU)
        kwargs["ncpu"] = config_.cpu_threads;          // ğŸ”„ ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
        kwargs["disable_pbar"] = true;
        kwargs["disable_log"] = true;
        kwargs["disable_update"] = true;               // ğŸ†• ç¦ç”¨ç‰ˆæœ¬æ£€æŸ¥ï¼Œå‡å°‘ç½‘ç»œä¾èµ–
        
        // CPUç‰¹å®šä¼˜åŒ–é…ç½®
        if (model_type == "streaming_asr") {
            // æµå¼æ¨¡å‹CPUä¼˜åŒ–
            kwargs["batch_size"] = 1;                  // ğŸ†• CPUå»ºè®®å•æ‰¹æ¬¡å¤„ç†
        } else if (model_type == "offline_asr") {
            // ç¦»çº¿æ¨¡å‹CPUä¼˜åŒ–
            kwargs["batch_size"] = 1;                  // ğŸ†• CPUå»ºè®®å•æ‰¹æ¬¡å¤„ç†
        }
        
        // å®ä¾‹åŒ–æ¨¡å‹
        model_obj = auto_model(**kwargs);
        
        std::ostringstream completion_log;
        completion_log << model_type << "æ¨¡å‹åŠ è½½å®Œæˆ (CPUæ¨¡å¼)ï¼Œè€—æ—¶: " 
                      << std::fixed << std::setprecision(1) << load_timer.ElapsedMs() << "ms";
        Logger::Info(completion_log.str());
        
        return true;
        
    } catch (const py::error_already_set& e) {
        std::string error_msg = model_type + "æ¨¡å‹åŠ è½½å¤±è´¥: " + std::string(e.what());
        Logger::Error(error_msg);
        return false;
    }
}

/**
 * CPUæ€§èƒ½ä¼˜åŒ– - CPUç‰ˆæœ¬æ–°å¢åŠŸèƒ½
 * 
 * ğŸ†• CPUç‰ˆæœ¬ä¸“ç”¨æ–¹æ³•:
 * 1. è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–å¤šçº¿ç¨‹åº“
 * 2. é…ç½®OpenMPå’ŒMKLçº¿ç¨‹æ•°
 * 3. è¿›ç¨‹ä¼˜å…ˆçº§è°ƒæ•´ (å¯é€‰)
 */
void FunASREngine::OptimizeCPUPerformance() {
    Logger::Info("å¯åŠ¨CPUæ€§èƒ½ä¼˜åŒ–...");
    
    try {
        // è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–CPUæ€§èƒ½
        std::string thread_str = std::to_string(config_.cpu_threads);
        
        // OpenMPçº¿ç¨‹æ•°
        setenv("OMP_NUM_THREADS", thread_str.c_str(), 1);
        
        // Intel MKLçº¿ç¨‹æ•° (å¦‚æœä½¿ç”¨Intel MKL)
        setenv("MKL_NUM_THREADS", thread_str.c_str(), 1);
        
        // NumExprçº¿ç¨‹æ•°
        setenv("NUMEXPR_NUM_THREADS", thread_str.c_str(), 1);
        
        // å¯é€‰ï¼šæå‡è¿›ç¨‹ä¼˜å…ˆçº§ (éœ€è¦æƒé™)
#ifdef __linux__
        if (setpriority(PRIO_PROCESS, 0, -5) == 0) {
            Logger::Info("è¿›ç¨‹ä¼˜å…ˆçº§å·²é€‚åº¦æå‡");
        }
#endif
        
        Logger::Info("CPUæ€§èƒ½ä¼˜åŒ–å®Œæˆ");
        
    } catch (const std::exception& e) {
        std::string warn_msg = "CPUæ€§èƒ½ä¼˜åŒ–éƒ¨åˆ†å¤±è´¥: " + std::string(e.what());
        Logger::Warn(warn_msg);
    }
}

/**
 * éŸ³é¢‘é‡é‡‡æ · - CPUç‰ˆæœ¬æ–°å¢åŠŸèƒ½
 * 
 * ğŸ†• è§£å†³24kHzéŸ³é¢‘é—®é¢˜:
 * ä½¿ç”¨çº¿æ€§æ’å€¼å®ç°é«˜è´¨é‡éŸ³é¢‘é‡é‡‡æ ·
 * æ”¯æŒä»»æ„é‡‡æ ·ç‡åˆ°16kHzçš„è½¬æ¢
 */
std::vector<float> FunASREngine::ResampleAudio(const std::vector<float>& audio_data, 
                                               int from_rate, int to_rate) {
    if (from_rate == to_rate) {
        return audio_data;
    }
    
    // ç®€å•çº¿æ€§æ’å€¼é‡é‡‡æ ·
    double ratio = static_cast<double>(to_rate) / from_rate;
    size_t new_size = static_cast<size_t>(audio_data.size() * ratio);
    std::vector<float> resampled(new_size);
    
    for (size_t i = 0; i < new_size; ++i) {
        double src_index = i / ratio;
        size_t idx = static_cast<size_t>(src_index);
        
        if (idx + 1 < audio_data.size()) {
            double frac = src_index - idx;
            resampled[i] = audio_data[idx] * (1.0 - frac) + audio_data[idx + 1] * frac;
        } else {
            resampled[i] = audio_data.back();
        }
    }
    
    std::ostringstream resample_log;
    resample_log << "éŸ³é¢‘é‡é‡‡æ ·å®Œæˆ: " << from_rate << "Hz â†’ " << to_rate << "Hz, "
                 << "æ ·æœ¬æ•°: " << audio_data.size() << " â†’ " << new_size;
    Logger::Info(resample_log.str());
    
    return resampled;
}

/**
 * ç¦»çº¿è¯­éŸ³è¯†åˆ« - CPUç‰ˆæœ¬å¢å¼º
 * 
 * ğŸ”„ CPUç‰ˆæœ¬æ”¹è¿›:
 * 1. å¢åŠ éŸ³é¢‘é‡é‡‡æ ·åŠŸèƒ½ (24kHzâ†’16kHz)
 * 2. å¢å¼ºé”™è¯¯å¤„ç†å’Œå¼‚å¸¸æ•è·
 * 3. ä¼˜åŒ–VADåˆ†æ®µå¤„ç†é€»è¾‘
 * 4. ä¿®å¤æ—¥å¿—æ ¼å¼åŒ–é—®é¢˜
 */
FunASREngine::RecognitionResult FunASREngine::OfflineRecognize(
    const std::vector<float>& audio_input,
    bool enable_vad,
    bool enable_punctuation) {
    
    RecognitionResult result;
    if (!initialized_) {
        Logger::Error("å¼•æ“æœªåˆå§‹åŒ–");
        return result;
    }
    
    try {
        Timer total_timer;
        
        // ğŸ†• éŸ³é¢‘é¢„å¤„ç† - é‡é‡‡æ ·æ”¯æŒ
        std::vector<float> audio_data = audio_input;
        if (config_.enable_audio_resampling && audio_data.size() > 0) {
            // å‡è®¾è¾“å…¥å¯èƒ½æ˜¯24kHz (åŸºäºä½ çš„æ—¥å¿—)ï¼Œé‡é‡‡æ ·åˆ°16kHz
            // å®é™…é¡¹ç›®ä¸­åº”è¯¥ä»AudioFileReaderè·å–çœŸå®é‡‡æ ·ç‡
            double input_duration = audio_data.size() / 24000.0; // å‡è®¾24kHz
            if (input_duration > 0) {
                audio_data = ResampleAudio(audio_input, 24000, 16000);
            }
        }
        
        std::string final_text;
        
        // VADåˆ†æ®µå¤„ç† - å¢å¼ºé”™è¯¯å¤„ç†
        enable_vad = false;
        if (enable_vad && audio_data.size() > 16000 * 5) { // å¤§äº5ç§’å¯ç”¨VAD
            Logger::Info("é•¿éŸ³é¢‘æ£€æµ‹ï¼Œå¯ç”¨VADåˆ†æ®µå¤„ç† (CPUæ¨¡å¼)");
            
            try {
                std::map<std::string, py::object> vad_cache;
                auto vad_result = DetectVoiceActivity(audio_data, vad_cache);
                
                if (vad_result.HasValidSegments()) {
                    std::ostringstream vad_log;
                    vad_log << "VADæ£€æµ‹åˆ°" << vad_result.segments.size() << "ä¸ªè¯­éŸ³æ®µ";
                    Logger::Info(vad_log.str());
                    
                    // å¯¹æ¯ä¸ªè¯­éŸ³æ®µè¿›è¡ŒASRè¯†åˆ«
                    std::vector<std::string> segment_texts;
                    for (const auto& segment : vad_result.segments) {
                        int start_sample = (segment.first * 16000) / 1000;
                        int end_sample = (segment.second * 16000) / 1000;
                        
                        if (start_sample >= 0 && end_sample <= static_cast<int>(audio_data.size()) && 
                            end_sample > start_sample) {
                            
                            std::vector<float> segment_audio(
                                audio_data.begin() + start_sample,
                                audio_data.begin() + end_sample
                            );
                            
                            // CPU ASRè¯†åˆ«å•ä¸ªæ®µ
                            py::array_t<float> audio_array = VectorToNumpy(segment_audio);
                            py::dict asr_kwargs;
                            asr_kwargs["input"] = audio_array;
                            
                            py::object asr_result = offline_model_.attr("generate")(**asr_kwargs);
                            auto parsed_result = ParseRecognitionResult(asr_result, 0);
                            
                            if (!parsed_result.text.empty()) {
                                segment_texts.push_back(parsed_result.text);
                            }
                        }
                    }
                    
                    // åˆå¹¶æ‰€æœ‰æ®µçš„æ–‡æœ¬
                    for (const auto& text : segment_texts) {
                        if (!final_text.empty()) final_text += " ";
                        final_text += text;
                    }
                } else {
                    Logger::Info("VADæœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³æ®µï¼Œä½¿ç”¨å®Œæ•´éŸ³é¢‘è¯†åˆ«");
                    enable_vad = false; // å›é€€åˆ°å®Œæ•´éŸ³é¢‘è¯†åˆ«
                }
            } catch (const std::exception& e) {
                std::string error_msg = "VADå¤„ç†å¼‚å¸¸ï¼Œå›é€€åˆ°å®Œæ•´éŸ³é¢‘è¯†åˆ«: " + std::string(e.what());
                Logger::Error(error_msg);
                enable_vad = false;
            }
        }
        
        // å®Œæ•´éŸ³é¢‘è¯†åˆ« (CPU)
        if (!enable_vad || final_text.empty()) {
            try {
                py::array_t<float> audio_array = VectorToNumpy(audio_data);
                py::dict asr_kwargs;
                asr_kwargs["input"] = audio_array;
                
                py::object asr_result = offline_model_.attr("generate")(**asr_kwargs);
                auto parsed_result = ParseRecognitionResult(asr_result, 0);
                final_text = parsed_result.text;
            } catch (const std::exception& e) {
                std::string error_msg = "ç¦»çº¿è¯†åˆ«å¼‚å¸¸: " + std::string(e.what());
                Logger::Error(error_msg);
                return result;
            }
        }
        
        // æ ‡ç‚¹ç¬¦å·æ¢å¤ (CPU)
        if (enable_punctuation && !final_text.empty()) {
            try {
                std::map<std::string, py::object> punc_cache;
                final_text = AddPunctuation(final_text, punc_cache);
            } catch (const std::exception& e) {
                std::string warn_msg = "æ ‡ç‚¹ç¬¦å·å¤„ç†å¼‚å¸¸: " + std::string(e.what());
                Logger::Warn(warn_msg);
            }
        }
        
        result.text = final_text;
        result.is_final = true;
        result.is_offline_result = true;
        result.inference_time_ms = total_timer.ElapsedMs();
        
        // æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        {
            std::lock_guard<std::mutex> lock(metrics_mutex_);
            current_metrics_.total_requests++;
            if (!result.IsEmpty()) {
                current_metrics_.success_requests++;
                double audio_duration_s = audio_data.size() / 16000.0;
                current_metrics_.offline_rtf = result.inference_time_ms / (audio_duration_s * 1000.0);
                current_metrics_.total_audio_processed_hours += audio_duration_s / 3600.0;
            }
        }
        
        // ä¿®å¤æ—¥å¿—æ ¼å¼åŒ–
        std::ostringstream result_log;
        result_log << "CPUç¦»çº¿è¯†åˆ«å®Œæˆ: '" << final_text.substr(0, 30) << "...', è€—æ—¶: " 
                  << std::fixed << std::setprecision(1) << result.inference_time_ms << "ms";
        Logger::Info(result_log.str());
        
    } catch (const std::exception& e) {
        std::string error_msg = "CPUç¦»çº¿è¯†åˆ«å¼‚å¸¸: " + std::string(e.what());
        Logger::Error(error_msg);
        current_metrics_.total_requests++;
    }
    
    return result;
}

/**
 * æµå¼è¯†åˆ« - CPUç‰ˆæœ¬ä¼˜åŒ–
 * 
 * ğŸ”„ CPUç‰ˆæœ¬æ”¹è¿›:
 * 1. CPUå¤šçº¿ç¨‹æ¨ç†ä¼˜åŒ–
 * 2. ä¿®å¤pybind11å¯¹è±¡ç”Ÿå‘½å‘¨æœŸé—®é¢˜
 * 3. å¢å¼ºç¼“å­˜çŠ¶æ€ç®¡ç†
 * 4. ä¿®å¤æ—¥å¿—æ ¼å¼åŒ–
 */
FunASREngine::RecognitionResult FunASREngine::StreamingRecognize(
    const std::vector<float>& audio_chunk,
    TwoPassSession& session,
    bool is_final) {
    
    RecognitionResult result;
    if (!initialized_) {
        Logger::Error("å¼•æ“æœªåˆå§‹åŒ–");
        return result;
    }
    
    try {
        Timer inference_timer;
        
        // è½¬æ¢éŸ³é¢‘æ•°æ®ä¸ºnumpyæ•°ç»„
        py::array_t<float> audio_array = VectorToNumpy(audio_chunk);
        
        // æ„å»ºæµå¼æ¨ç†å‚æ•° (CPUé…ç½®)
        py::dict kwargs;
        kwargs["input"] = audio_array;
        kwargs["is_final"] = is_final;
        kwargs["chunk_size"] = py::make_tuple(
            session.chunk_size[0],
            session.chunk_size[1],
            session.chunk_size[2]
        );
        kwargs["encoder_chunk_look_back"] = session.encoder_chunk_look_back;
        kwargs["decoder_chunk_look_back"] = session.decoder_chunk_look_back;
        
        // æ·»åŠ ç¼“å­˜çŠ¶æ€ (ä¿®å¤pybind11å¯¹è±¡ç”Ÿå‘½å‘¨æœŸé—®é¢˜)
        if (!session.streaming_cache.empty()) {
            py::dict cache_dict;
            for (const auto& item : session.streaming_cache) {
                cache_dict[py::str(item.first)] = item.second;
            }
            kwargs["cache"] = cache_dict;
        }
        
        // æ‰§è¡ŒCPUæµå¼æ¨ç†
        py::object py_result = streaming_model_.attr("generate")(**kwargs);
        
        // ğŸ”„ æ›´æ–°ç¼“å­˜çŠ¶æ€ - ä¿®å¤pybind11å¯¹è±¡èµ‹å€¼é—®é¢˜
        if (kwargs.contains("cache")) {
            py::dict updated_cache = kwargs["cache"];
            session.streaming_cache.clear();
            for (auto item : updated_cache) {
                // ä¿®å¤ï¼šä½¿ç”¨reinterpret_borrowæ˜¾å¼è½¬æ¢handleåˆ°object
                session.streaming_cache[item.first.cast<std::string>()] = 
                    py::reinterpret_borrow<py::object>(item.second);
            }
        }
        
        // è§£æç»“æœ
        result = ParseRecognitionResult(py_result, inference_timer.ElapsedMs());
        result.is_final = is_final;
        result.is_online_result = true;
        
        // æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        {
            std::lock_guard<std::mutex> lock(metrics_mutex_);
            current_metrics_.total_requests++;
            if (!result.IsEmpty()) {
                current_metrics_.success_requests++;
                double chunk_duration_s = audio_chunk.size() / 16000.0;
                current_metrics_.streaming_rtf = result.inference_time_ms / (chunk_duration_s * 1000.0);
                current_metrics_.online_latency_ms = result.inference_time_ms;
                current_metrics_.total_audio_processed_hours += chunk_duration_s / 3600.0;
            }
        }
        
        // ä¿®å¤æ—¥å¿—æ ¼å¼åŒ–
        std::ostringstream stream_log;
        stream_log << "CPUæµå¼è¯†åˆ«: '" << result.text << "', è€—æ—¶: " 
                  << std::fixed << std::setprecision(1) << result.inference_time_ms << "ms, RTF: "
                  << std::fixed << std::setprecision(4) << current_metrics_.streaming_rtf;
        Logger::Info(stream_log.str());
        
    } catch (const std::exception& e) {
        std::string error_msg = "CPUæµå¼è¯†åˆ«å¼‚å¸¸: " + std::string(e.what());
        Logger::Error(error_msg);
        current_metrics_.total_requests++;
    }
    
    return result;
}

/**
 * CPUå†…å­˜ä½¿ç”¨é‡è·å– - æ›¿ä»£GPUæ˜¾å­˜ç›‘æ§
 * 
 * ğŸ†• CPUç‰ˆæœ¬æ–°å¢åŠŸèƒ½:
 * é€šè¿‡è¯»å–/proc/meminfoè·å–ç³»ç»Ÿå†…å­˜ä½¿ç”¨æƒ…å†µ
 */
double FunASREngine::GetCPUMemoryUsage() {
    try {
#ifdef __linux__
        std::ifstream meminfo("/proc/meminfo");
        if (!meminfo.is_open()) {
            return 0.0;
        }
        
        std::string line;
        long mem_total = 0, mem_available = 0;
        
        while (std::getline(meminfo, line)) {
            if (line.find("MemTotal:") == 0) {
                sscanf(line.c_str(), "MemTotal: %ld kB", &mem_total);
            } else if (line.find("MemAvailable:") == 0) {
                sscanf(line.c_str(), "MemAvailable: %ld kB", &mem_available);
            }
        }
        
        if (mem_total > 0 && mem_available > 0) {
            double used_gb = (mem_total - mem_available) / (1024.0 * 1024.0);
            return used_gb;
        }
#endif
    } catch (...) {
        // é™é»˜å¤„ç†å¼‚å¸¸
    }
    return 0.0;
}

// ============ å…¶ä»–æ–¹æ³•çš„CPUç‰ˆæœ¬é€‚é… ============

/**
 * 2Passè¯†åˆ« - CPUå¹¶è¡Œä¼˜åŒ–ç‰ˆæœ¬
 * åŸºæœ¬é€»è¾‘ä¿æŒä¸å˜ï¼Œä½†å¢å¼ºäº†é”™è¯¯å¤„ç†å’Œæ—¥å¿—ä¿®å¤
 */
void FunASREngine::TwoPassRecognize(
    const std::vector<float>& audio_chunk,
    TwoPassSession& session,
    std::vector<RecognitionResult>& results) {
    
    if (!initialized_) {
        Logger::Error("å¼•æ“æœªåˆå§‹åŒ–");
        return;
    }
    
    try {
        Timer total_timer;
        
        // æ·»åŠ éŸ³é¢‘å—åˆ°ç¼“å†²åŒº
        session.audio_buffer.insert(session.audio_buffer.end(),
                                   audio_chunk.begin(), audio_chunk.end());
        
        // 1. CPUå¹¶è¡Œæ‰§è¡ŒVADæ£€æµ‹å’Œæµå¼è¯†åˆ«
        std::future<VADResult> vad_future = std::async(std::launch::async, 
            [this, &audio_chunk, &session]() {
                return DetectVoiceActivity(audio_chunk, session.vad_cache);
            });
            
        std::future<RecognitionResult> streaming_future = std::async(std::launch::async,
            [this, &audio_chunk, &session]() {
                return StreamingRecognize(audio_chunk, session, false);
            });
        
        // 2. è·å–æµå¼è¯†åˆ«ç»“æœ (ç«‹å³è¿”å›ç»™ç”¨æˆ·)
        auto streaming_result = streaming_future.get();
        if (!streaming_result.IsEmpty()) {
            streaming_result.is_online_result = true;
            results.push_back(streaming_result);
        }
        
        // 3. å¤„ç†VADç»“æœ
        auto vad_result = vad_future.get();
        current_metrics_.vad_processing_ms = vad_result.inference_time_ms;
        
        // 4. æ£€æµ‹è¯­éŸ³ç»“æŸç‚¹
        if (vad_result.speech_end_ms != -1) {
            session.is_speaking = false;
            Logger::Info("æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œå¯åŠ¨ç¦»çº¿ç²¾åŒ–å¤„ç†");
            
            // æå–å®Œæ•´è¯­éŸ³æ®µè¿›è¡Œç¦»çº¿è¯†åˆ«
            std::vector<float> complete_segment = session.audio_buffer;
            
            // CPUå¼‚æ­¥æ‰§è¡Œç¦»çº¿ç²¾åŒ–
            std::thread([this, complete_segment, &session]() {
                Timer offline_timer;
                auto offline_result = OfflineRecognize(complete_segment, false, true);
                if (!offline_result.IsEmpty()) {
                    offline_result.is_offline_result = true;
                    offline_result.is_final = true;
                    current_metrics_.offline_refinement_ms = offline_timer.ElapsedMs();
                    
                    std::ostringstream offline_log;
                    offline_log << "ç¦»çº¿ç²¾åŒ–å®Œæˆ: '" << offline_result.text << "'";
                    Logger::Info(offline_log.str());
                }
                session.Reset();
            }).detach();
            
        } else if (vad_result.speech_start_ms != -1) {
            session.is_speaking = true;
        }
        
        // æ›´æ–°2Passæ¨¡å¼æ€§èƒ½æŒ‡æ ‡
        {
            std::lock_guard<std::mutex> lock(metrics_mutex_);
            double chunk_duration_s = audio_chunk.size() / 16000.0;
            current_metrics_.two_pass_rtf = total_timer.ElapsedMs() / (chunk_duration_s * 1000.0);
            current_metrics_.end_to_end_latency_ms = total_timer.ElapsedMs();
        }
        
    } catch (const std::exception& e) {
        std::string error_msg = "CPU 2Passè¯†åˆ«å¼‚å¸¸: " + std::string(e.what());
        Logger::Error(error_msg);
    }
}

/**
 * VADæ£€æµ‹ - CPUç‰ˆæœ¬ (åŸºæœ¬é€»è¾‘ä¿æŒä¸å˜ï¼Œä¿®å¤æ—¥å¿—æ ¼å¼åŒ–)
 */
FunASREngine::VADResult FunASREngine::DetectVoiceActivity(
    const std::vector<float>& audio_data,
    std::map<std::string, py::object>& vad_cache,
    int max_single_segment_time) {
    
    VADResult result;
    try {
        Timer vad_timer;
        
        // è½¬æ¢éŸ³é¢‘æ•°æ®
        py::array_t<float> audio_array = VectorToNumpy(audio_data);
        
        // æ„å»ºVADå‚æ•°
        py::dict kwargs;
        kwargs["input"] = audio_array;
        kwargs["max_single_segment_time"] = max_single_segment_time;
        
        // æ·»åŠ ç¼“å­˜çŠ¶æ€
        if (!vad_cache.empty()) {
            py::dict cache_dict;
            for (const auto& item : vad_cache) {
                cache_dict[py::str(item.first)] = item.second;
            }
            kwargs["cache"] = cache_dict;
        }
        
        // æ‰§è¡ŒCPU VADæ¨ç†
        py::object vad_py_result = vad_model_.attr("generate")(**kwargs);
        
        // æ›´æ–°ç¼“å­˜ - ä¿®å¤pybind11å¯¹è±¡èµ‹å€¼é—®é¢˜
        if (kwargs.contains("cache")) {
            py::dict updated_cache = kwargs["cache"];
            vad_cache.clear();
            for (auto item : updated_cache) {
                vad_cache[item.first.cast<std::string>()] = 
                    py::reinterpret_borrow<py::object>(item.second);
            }
        }
        
        result = ParseVADResult(vad_py_result, vad_timer.ElapsedMs());
        
    } catch (const std::exception& e) {
        std::string error_msg = "CPU VADæ£€æµ‹å¼‚å¸¸: " + std::string(e.what());
        Logger::Error(error_msg);
    }
    
    return result;
}

/**
 * æ ‡ç‚¹ç¬¦å·æ¢å¤ - CPUç‰ˆæœ¬ (åŸºæœ¬é€»è¾‘ä¿æŒä¸å˜ï¼Œä¿®å¤æ—¥å¿—æ ¼å¼åŒ–)
 */
std::string FunASREngine::AddPunctuation(const std::string& text,
                                         std::map<std::string, py::object>& punc_cache) {
    if (text.empty() || punc_model_.is_none()) {
        return text;
    }
    
    try {
        Timer punc_timer;
        
        // æ„å»ºæ ‡ç‚¹ç¬¦å·æ¢å¤å‚æ•°
        py::dict kwargs;
        kwargs["input"] = text;
        
        // æ·»åŠ ç¼“å­˜çŠ¶æ€
        if (!punc_cache.empty()) {
            py::dict cache_dict;
            for (const auto& item : punc_cache) {
                cache_dict[py::str(item.first)] = item.second;
            }
            kwargs["cache"] = cache_dict;
        }
        
        // æ‰§è¡ŒCPUæ ‡ç‚¹ç¬¦å·æ¢å¤
        py::object punc_result = punc_model_.attr("generate")(**kwargs);
        
        // æ›´æ–°ç¼“å­˜ - ä¿®å¤pybind11å¯¹è±¡èµ‹å€¼é—®é¢˜
        if (kwargs.contains("cache")) {
            py::dict updated_cache = kwargs["cache"];
            punc_cache.clear();
            for (auto item : updated_cache) {
                punc_cache[item.first.cast<std::string>()] = 
                    py::reinterpret_borrow<py::object>(item.second);
            }
        }
        
        // è§£æç»“æœ
        if (py::isinstance<py::list>(punc_result)) {
            py::list result_list = punc_result;
            if (result_list.size() > 0) {
                py::dict first_result = result_list[0];
                if (first_result.contains("text")) {
                    std::string punctuated_text = first_result["text"].cast<std::string>();
                    current_metrics_.punctuation_ms = punc_timer.ElapsedMs();
                    return punctuated_text;
                }
            }
        }
        
    } catch (const std::exception& e) {
        std::string error_msg = "CPUæ ‡ç‚¹ç¬¦å·å¤„ç†å¼‚å¸¸: " + std::string(e.what());
        Logger::Error(error_msg);
    }
    
    return text; // å‡ºé”™æ—¶è¿”å›åŸæ–‡æœ¬
}

// ============ è¾…åŠ©æ–¹æ³•å®ç° (åŸºæœ¬ä¿æŒä¸å˜) ============

py::array_t<float> FunASREngine::VectorToNumpy(const std::vector<float>& data) {
    return py::array_t<float>(
        data.size(),
        data.data(),
        py::cast(this)
    );
}

FunASREngine::RecognitionResult FunASREngine::ParseRecognitionResult(
    const py::object& result, double inference_time_ms) {
    
    RecognitionResult parsed;
    parsed.inference_time_ms = inference_time_ms;
    
    try {
        if (py::isinstance<py::list>(result)) {
            py::list result_list = result;
            if (result_list.size() > 0) {
                py::dict first_result = result_list[0];
                if (first_result.contains("text")) {
                    parsed.text = first_result["text"].cast<std::string>();
                }
            }
        }
    } catch (const std::exception& e) {
        std::string error_msg = "è¯†åˆ«ç»“æœè§£æå¼‚å¸¸: " + std::string(e.what());
        Logger::Error(error_msg);
    }
    
    return parsed;
}

FunASREngine::VADResult FunASREngine::ParseVADResult(
    const py::object& result, double inference_time_ms) {
    
    VADResult parsed;
    parsed.inference_time_ms = inference_time_ms;
    
    try {
        if (py::isinstance<py::list>(result)) {
            py::list result_list = result;
            if (result_list.size() > 0) {
                py::dict first_result = result_list[0];
                if (first_result.contains("value")) {
                    py::list segments = first_result["value"];
                    for (auto segment : segments) {
                        py::list seg_pair = py::reinterpret_borrow<py::list>(segment);
                        if (seg_pair.size() >= 2) {
                            int64_t start = seg_pair[0].cast<int64_t>();
                            int64_t end = seg_pair[1].cast<int64_t>();
                            parsed.segments.emplace_back(start, end);
                            
                            if (start != -1 && parsed.speech_start_ms == -1) {
                                parsed.speech_start_ms = start;
                            }
                            if (end != -1) {
                                parsed.speech_end_ms = end;
                            }
                        }
                    }
                    parsed.has_speech = !parsed.segments.empty();
                }
            }
        }
    } catch (const std::exception& e) {
        std::string error_msg = "VADç»“æœè§£æå¼‚å¸¸: " + std::string(e.what());
        Logger::Error(error_msg);
    }
    
    return parsed;
}
// ============ æ€§èƒ½æµ‹è¯•å®ç° ============

bool FunASREngine::RunPerformanceTests() {
    if (!initialized_ || test_audio_files_.empty()) {
        Logger::Error("å¼•æ“æœªåˆå§‹åŒ–æˆ–æ— æµ‹è¯•æ–‡ä»¶");
        return false;
    }

    Logger::Info("ğŸ§ª å¼€å§‹FunASR CPUå®Œæ•´æ€§èƒ½æµ‹è¯•å¥—ä»¶...");
    testing_active_ = true;
    
    test_thread_ = std::thread([this]() {
        try {
            Timer total_test_timer;
            
            if (config_.enable_offline_test) {
                Logger::Info("1ï¸âƒ£ ç¦»çº¿è¯†åˆ«æ€§èƒ½æµ‹è¯• (CPUæ¨¡å¼)...");
                auto offline_metrics = TestOfflinePerformance();
                UpdateMetrics(offline_metrics);
            }
            
            Logger::Info("ğŸ‰ å®Œæ•´CPUæ€§èƒ½æµ‹è¯•å¥—ä»¶å®Œæˆï¼æ€»è€—æ—¶: {:.1f}ç§’", 
                        total_test_timer.ElapsedMs() / 1000.0);
        } catch (const std::exception& e) {
            Logger::Error("æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {}", e.what());
        }
        
        testing_active_ = false; // æ ‡è®°æµ‹è¯•å®Œæˆ
    });
    
    return true;
}

PerformanceMetrics FunASREngine::TestOfflinePerformance() {
    PerformanceMetrics metrics;
    int test_count = std::min(20, static_cast<int>(test_audio_files_.size()));
    std::vector<double> rtf_values;
    double total_audio_duration = 0.0;
    
    Logger::Info("å¼€å§‹ç¦»çº¿æµ‹è¯•ï¼Œç›®æ ‡å¤„ç†{}ä¸ªéŸ³é¢‘æ–‡ä»¶", test_count);
    
    for (int i = 0; i < test_count; ++i) {
        const auto& file_path = test_audio_files_[i];
        Logger::Info("å¤„ç†éŸ³é¢‘æ–‡ä»¶ [{}/{}]: {}", i+1, test_count, file_path);
        
        auto audio_data = AudioFileReader::ReadWavFile(file_path);
        if (!audio_data.IsValid()) {
            Logger::Warn("è·³è¿‡æ— æ•ˆéŸ³é¢‘æ–‡ä»¶: {}", file_path);
            continue;
        }

        Timer test_timer;
        Logger::Info("å¼€å§‹è¯†åˆ«ï¼ŒéŸ³é¢‘æ—¶é•¿: {:.2f}ç§’", audio_data.duration_seconds);
        
        auto result = OfflineRecognize(audio_data.samples, true, true);
        double elapsed_ms = test_timer.ElapsedMs();
        
        if (!result.IsEmpty()) {
            double rtf = elapsed_ms / (audio_data.duration_seconds * 1000.0);
            rtf_values.push_back(rtf);
            total_audio_duration += audio_data.duration_seconds;
            
            Logger::Info("è¯†åˆ«å®Œæˆ [{}/{}]: RTF={:.4f}, è€—æ—¶={:.1f}ms, ç»“æœ: '{}'", 
                        i+1, test_count, rtf, elapsed_ms, result.text.substr(0, 50));
        } else {
            Logger::Error("è¯†åˆ«å¤±è´¥ [{}/{}]: è¿”å›ç©ºç»“æœ", i+1, test_count);
        }
    }
    
    if (!rtf_values.empty()) {
        double sum = 0;
        for (double rtf : rtf_values) sum += rtf;
        metrics.offline_rtf = sum / rtf_values.size();
        metrics.total_audio_processed_hours = total_audio_duration / 3600.0;
        metrics.test_files_count = static_cast<int>(rtf_values.size());
        
        Logger::Info("ç¦»çº¿æµ‹è¯•å®Œæˆ: æˆåŠŸ{}/{}ä¸ªæ–‡ä»¶, å¹³å‡RTF={:.4f}, æ€»æ—¶é•¿={:.2f}å°æ—¶", 
                    rtf_values.size(), test_count, metrics.offline_rtf, metrics.total_audio_processed_hours);
    } else {
        Logger::Error("ç¦»çº¿æµ‹è¯•å¤±è´¥: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•éŸ³é¢‘æ–‡ä»¶");
    }
    
    return metrics;
}



PerformanceMetrics FunASREngine::TestStreamingPerformance() {
    PerformanceMetrics metrics;
    int test_count = std::min(15, static_cast<int>(test_audio_files_.size()));
    std::vector<double> rtf_values, latency_values;
    Logger::Info("æµå¼æµ‹è¯•ä½¿ç”¨{}ä¸ªéŸ³é¢‘æ–‡ä»¶", test_count);

    for (int i = 0; i < test_count; ++i) {
        const auto& file_path = test_audio_files_[i];
        auto audio_data = AudioFileReader::ReadWavFile(file_path);
        if (!audio_data.IsValid()) continue;
        auto chunks = SimulateStreamingChunks(audio_data.samples);
        TwoPassSession session;
        for (size_t chunk_idx = 0; chunk_idx < chunks.size(); ++chunk_idx) {
            bool is_final = (chunk_idx == chunks.size() - 1);
            auto result = StreamingRecognize(chunks[chunk_idx], session, is_final);
            if (!result.IsEmpty()) {
                double chunk_duration_ms = chunks[chunk_idx].size() / 16.0; // 16kHz
                double rtf = result.inference_time_ms / chunk_duration_ms;
                rtf_values.push_back(rtf);
                latency_values.push_back(result.inference_time_ms);
            }
        }
        std::ostringstream oss;
        oss << "æµå¼æµ‹è¯• [" << (i+1) << "/" << test_count << "]: "
            << std::fixed << std::setprecision(1) << audio_data.duration_seconds << "ç§’, "
            << chunks.size() << "ä¸ªåˆ†å—";
        Logger::Info(oss.str());
    }
    if (!rtf_values.empty()) {
        double sum_rtf = 0, sum_latency = 0;
        for (double rtf : rtf_values) sum_rtf += rtf;
        for (double lat : latency_values) sum_latency += lat;
        metrics.streaming_rtf = sum_rtf / rtf_values.size();
        metrics.online_latency_ms = sum_latency / latency_values.size();
        metrics.end_to_end_latency_ms = metrics.online_latency_ms;
        std::ostringstream oss;
        oss << "æµå¼æµ‹è¯•å®Œæˆ: å¹³å‡RTF=" << std::fixed << std::setprecision(4) << metrics.streaming_rtf 
            << ", å¹³å‡å»¶è¿Ÿ=" << std::fixed << std::setprecision(1) << metrics.online_latency_ms << "ms";
        Logger::Info(oss.str());
    }
    return metrics;
}


PerformanceMetrics FunASREngine::TestTwoPassPerformance() {
    PerformanceMetrics metrics;
    int test_count = std::min(10, static_cast<int>(test_audio_files_.size()));
    std::vector<double> rtf_values;
    Logger::Info("2Passæµ‹è¯•ä½¿ç”¨{}ä¸ªéŸ³é¢‘æ–‡ä»¶", test_count);

    for (int i = 0; i < test_count; ++i) {
        const auto& file_path = test_audio_files_[i];
        auto audio_data = AudioFileReader::ReadWavFile(file_path);
        if (!audio_data.IsValid()) continue;
        auto chunks = SimulateStreamingChunks(audio_data.samples);
        TwoPassSession session;
        std::vector<RecognitionResult> results;
        Timer two_pass_timer;
        for (size_t chunk_idx = 0; chunk_idx < chunks.size(); ++chunk_idx) {
            TwoPassRecognize(chunks[chunk_idx], session, results);
        }
        double elapsed_ms = two_pass_timer.ElapsedMs();
        double rtf = elapsed_ms / (audio_data.duration_seconds * 1000.0);
        rtf_values.push_back(rtf);
        std::ostringstream oss;
        oss << "2Passæµ‹è¯• [" << (i+1) << "/" << test_count << "]: "
            << std::fixed << std::setprecision(1) << audio_data.duration_seconds << "ç§’, "
            << "RTF=" << std::setprecision(4) << rtf << ", è¾“å‡º" << results.size() << "ä¸ªç»“æœ";
        Logger::Info(oss.str());
    }
    if (!rtf_values.empty()) {
        double sum = 0;
        for (double rtf : rtf_values) sum += rtf;
        metrics.two_pass_rtf = sum / rtf_values.size();
        std::ostringstream oss;
        oss << "2Passæµ‹è¯•å®Œæˆ: å¹³å‡RTF=" << std::fixed << std::setprecision(4) << metrics.two_pass_rtf;
        Logger::Info(oss.str());
    }
    return metrics;
}


PerformanceMetrics FunASREngine::TestConcurrentPerformance() {
    PerformanceMetrics metrics;
    const int num_workers = config_.max_concurrent_sessions;
    const int files_per_worker = std::max(1, static_cast<int>(test_audio_files_.size()) / num_workers);
    std::ostringstream start_log;
    start_log << "å¯åŠ¨" << num_workers << "è·¯å¹¶å‘æµ‹è¯•ï¼Œæ¯è·¯å¤„ç†" << files_per_worker << "ä¸ªæ–‡ä»¶";
    Logger::Info(start_log.str());

    std::vector<std::future<void>> futures;
    std::vector<PerformanceMetrics> worker_results(num_workers);
    std::atomic<int> active_sessions{0};
    Timer concurrent_timer;

    for (int i = 0; i < num_workers; ++i) {
        int start_idx = i * files_per_worker;
        int end_idx = std::min(start_idx + files_per_worker, static_cast<int>(test_audio_files_.size()));
        std::vector<std::string> worker_files(
            test_audio_files_.begin() + start_idx,
            test_audio_files_.begin() + end_idx
        );
        futures.emplace_back(std::async(std::launch::async,
            [this, i, worker_files, &active_sessions, &worker_results]() {
                ConcurrentTestWorker(i, worker_files, active_sessions, worker_results);
            })
        );
    }

    for (auto& future : futures) future.wait();

    double total_time_s = concurrent_timer.ElapsedMs() / 1000.0;
    double total_rtf = 0;
    int valid_results = 0;
    for (const auto& result : worker_results) {
        if (result.streaming_rtf > 0) {
            total_rtf += result.streaming_rtf;
            valid_results++;
        }
    }
    if (valid_results > 0) {
        metrics.streaming_rtf = total_rtf / valid_results;
    }
    metrics.concurrent_sessions = num_workers;

    std::ostringstream oss;
    oss << "å¹¶å‘æµ‹è¯•å®Œæˆ: " << num_workers << "è·¯å¹¶å‘, å¹³å‡RTF=" 
        << std::fixed << std::setprecision(4) << metrics.streaming_rtf 
        << ", æ€»è€—æ—¶=" << std::fixed << std::setprecision(1) << total_time_s << "ç§’";
    Logger::Info(oss.str());

    return metrics;
}


void FunASREngine::ConcurrentTestWorker(
    int worker_id,
    const std::vector<std::string>& worker_files,
    std::atomic<int>& active_sessions,
    std::vector<PerformanceMetrics>& results) {
    try {
        active_sessions++;
        PerformanceMetrics worker_metrics;
        std::vector<double> rtf_values;
        Timer worker_timer;
        for (const auto& file_path : worker_files) {
            auto audio_data = AudioFileReader::ReadWavFile(file_path);
            if (!audio_data.IsValid()) continue;
            auto chunks = SimulateStreamingChunks(audio_data.samples);
            TwoPassSession session;
            for (const auto& chunk : chunks) {
                auto result = StreamingRecognize(chunk, session, false);
                double elapsed_ms = worker_timer.ElapsedMs();
                double rtf = elapsed_ms / (audio_data.duration_seconds * 1000.0);
                rtf_values.push_back(rtf);
            }
        }
        if (!rtf_values.empty()) {
            double sum = 0;
            for (double rtf : rtf_values) sum += rtf;
            worker_metrics.streaming_rtf = sum / rtf_values.size();
        }
        results[worker_id] = worker_metrics;
        active_sessions--;
        std::ostringstream oss;
        oss << "å¹¶å‘Worker-" << worker_id << " å®Œæˆ: å¤„ç†" << worker_files.size()
            << "ä¸ªæ–‡ä»¶, å¹³å‡RTF=" << std::fixed << std::setprecision(4) << worker_metrics.streaming_rtf;
        Logger::Info(oss.str());
    } catch (const std::exception& e) {
        std::ostringstream oss;
        oss << "å¹¶å‘Worker-" << worker_id << " å¼‚å¸¸: " << e.what();
        Logger::Error(oss.str());
        active_sessions--;
    }
}

std::vector<std::vector<float>> FunASREngine::SimulateStreamingChunks(
    const std::vector<float>& audio_data, double chunk_duration_ms) {
    std::vector<std::vector<float>> chunks;
    const int chunk_samples = static_cast<int>((chunk_duration_ms / 1000.0) * 16000); // å‡è®¾16kHz
    for (size_t i = 0; i < audio_data.size(); i += chunk_samples) {
        size_t end_idx = std::min(i + chunk_samples, audio_data.size());
        chunks.emplace_back(audio_data.begin() + i, audio_data.begin() + end_idx);
    }
    std::ostringstream oss;
    oss << "æ¨¡æ‹Ÿæµå¼åˆ†å—å®Œæˆï¼Œåˆ†å—æ•°é‡: " << chunks.size() 
        << ", æ¯å—æ—¶é•¿: " << chunk_duration_ms << "ms";
    Logger::Info(oss.str());
    return chunks;
}


/**
 * è·å–æ€§èƒ½æŒ‡æ ‡ - CPUç‰ˆæœ¬ä¿®å¤
 * 
 * ğŸ”„ ä¿®å¤è¯´æ˜ï¼šå°†GetGPUMemoryUsage()æ”¹ä¸ºGetCPUMemoryUsage()
 */
PerformanceMetrics FunASREngine::GetPerformanceMetrics() const {
    std::lock_guard<std::mutex> lock(metrics_mutex_);
    auto metrics = current_metrics_;
    // ä¿®æ­£ï¼šè°ƒç”¨æ­£ç¡®çš„CPUå†…å­˜è·å–æ–¹æ³•
    metrics.gpu_memory_gb = const_cast<FunASREngine*>(this)->GetCPUMemoryUsage();
    return metrics;
}


/**
 * åŠ è½½æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ - CPUç‰ˆæœ¬é€‚é…
 * 
 * ğŸ”„ ä¸»è¦åŠŸèƒ½:
 * 1. æ‰«æéŸ³é¢‘æ–‡ä»¶ç›®å½•
 * 2. éšæœºé€‰æ‹©æµ‹è¯•æ–‡ä»¶ï¼ˆå¦‚æœæ•°é‡è¿‡å¤šï¼‰
 * 3. é¢„æ£€æŸ¥æ–‡ä»¶æœ‰æ•ˆæ€§
 * 4. ä¿®å¤æ—¥å¿—æ ¼å¼åŒ–é—®é¢˜
 */
bool FunASREngine::LoadTestAudioFiles() {
    std::ostringstream scan_log;
    scan_log << "æ‰«ææµ‹è¯•éŸ³é¢‘æ–‡ä»¶ç›®å½•: " << config_.audio_files_dir;
    Logger::Info(scan_log.str());
    
    // æ‰«æWAVæ–‡ä»¶
    auto all_wav_files = AudioFileReader::ScanWavFiles(config_.audio_files_dir);
    if (all_wav_files.empty()) {
        std::string error_msg = "æœªæ‰¾åˆ°WAVéŸ³é¢‘æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ç›®å½•: " + config_.audio_files_dir;
        Logger::Error(error_msg);
        return false;
    }
    
    // é€‰æ‹©æµ‹è¯•æ–‡ä»¶ (å¦‚æœæ–‡ä»¶å¤ªå¤šï¼Œéšæœºé€‰æ‹©ä¸€éƒ¨åˆ†)
    if (all_wav_files.size() > static_cast<size_t>(config_.max_test_files)) {
        std::ostringstream select_log;
        select_log << "éŸ³é¢‘æ–‡ä»¶æ€»æ•°(" << all_wav_files.size() 
                   << ")è¶…è¿‡æœ€å¤§æµ‹è¯•æ•°(" << config_.max_test_files << "), å°†éšæœºé€‰æ‹©";
        Logger::Info(select_log.str());
        
        // éšæœºæ‰“ä¹±å¹¶é€‰æ‹©å‰Nä¸ª
        std::random_device rd;
        std::mt19937 gen(rd());
        std::shuffle(all_wav_files.begin(), all_wav_files.end(), gen);
        all_wav_files.resize(config_.max_test_files);
    }
    
    test_audio_files_ = std::move(all_wav_files);
    
    std::ostringstream selected_log;
    selected_log << "å·²é€‰æ‹©" << test_audio_files_.size() << "ä¸ªéŸ³é¢‘æ–‡ä»¶ç”¨äºæµ‹è¯•";
    Logger::Info(selected_log.str());
    
    // é¢„æ£€æŸ¥å‡ ä¸ªæ–‡ä»¶ç¡®ä¿å¯è¯»æ€§
    int valid_files = 0;
    for (int i = 0; i < std::min(5, static_cast<int>(test_audio_files_.size())); ++i) {
        auto audio_data = AudioFileReader::ReadWavFile(test_audio_files_[i]);
        if (audio_data.IsValid()) {
            valid_files++;
        }
    }
    
    if (valid_files == 0) {
        Logger::Error("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶å¯ä¾›æµ‹è¯•");
        return false;
    }
    
    std::ostringstream check_log;
    check_log << "éŸ³é¢‘æ–‡ä»¶é¢„æ£€æŸ¥å®Œæˆï¼Œæœ‰æ•ˆæ–‡ä»¶ç‡: " << valid_files << "/5";
    Logger::Info(check_log.str());
    
    return true;
}


void FunASREngine::UpdateMetrics(const PerformanceMetrics& new_metrics) {
    std::lock_guard<std::mutex> lock(metrics_mutex_);
    // å®é™…æ›´æ–°é€»è¾‘ï¼ŒæŒ‰å­—æ®µåˆ†åˆ«å¤„ç†
    if (new_metrics.streaming_rtf > 0) current_metrics_.streaming_rtf = new_metrics.streaming_rtf;
    if (new_metrics.offline_rtf > 0) current_metrics_.offline_rtf = new_metrics.offline_rtf;
    if (new_metrics.two_pass_rtf > 0) current_metrics_.two_pass_rtf = new_metrics.two_pass_rtf;
    if (new_metrics.end_to_end_latency_ms > 0) current_metrics_.end_to_end_latency_ms = new_metrics.end_to_end_latency_ms;
    if (new_metrics.online_latency_ms > 0) current_metrics_.online_latency_ms = new_metrics.online_latency_ms;
    if (new_metrics.concurrent_sessions > 0) current_metrics_.concurrent_sessions = new_metrics.concurrent_sessions;
    if (new_metrics.total_audio_processed_hours > 0) current_metrics_.total_audio_processed_hours += new_metrics.total_audio_processed_hours;
    if (new_metrics.test_files_count > 0) current_metrics_.test_files_count = new_metrics.test_files_count;
    current_metrics_.gpu_memory_gb = new_metrics.gpu_memory_gb;

    // ä¿®å¤ï¼šæ—¥å¿—æ ¼å¼ï¼ˆæ ‡å‡† C++ æµå¼æ‹¼æ¥ï¼Œä¿è¯è¾“å‡ºå†…å®¹æ¸…æ™°ï¼‰
    std::ostringstream oss;
    oss << "æ›´æ–°æ€§èƒ½æŒ‡æ ‡ï¼š"
        << "æµå¼RTF=" << std::fixed << std::setprecision(4) << current_metrics_.streaming_rtf << ", "
        << "ç¦»çº¿RTF=" << std::fixed << std::setprecision(4) << current_metrics_.offline_rtf << ", "
        << "2PassRTF=" << std::fixed << std::setprecision(4) << current_metrics_.two_pass_rtf << ", "
        << "å¹¶å‘=" << current_metrics_.concurrent_sessions << ", "
        << "æ€»æ—¶é•¿=" << std::fixed << std::setprecision(1) << current_metrics_.total_audio_processed_hours << "h";
    Logger::Info(oss.str());
}
